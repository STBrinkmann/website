<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Health Geography | GeoBrinkmann</title>
    <link>/tag/health-geography/</link>
      <atom:link href="/tag/health-geography/index.xml" rel="self" type="application/rss+xml" />
    <description>Health Geography</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 05 Jul 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hub8298344815fb61130442b7c2888b4e0_27889_512x512_fill_lanczos_center_2.png</url>
      <title>Health Geography</title>
      <link>/tag/health-geography/</link>
    </image>
    
    <item>
      <title>GVI: Greenness Visibility Index R package</title>
      <link>/publication/gvi-greenness-visibility-index-r-package/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      <guid>/publication/gvi-greenness-visibility-index-r-package/</guid>
      <description>&lt;p&gt;The GVI R package helps researchers compute the Greenness Visibility Index (GVI) presented by &lt;a href=&#34;https://doi.org/10.1016/j.scitotenv.2020.143050&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Labib, Huck and Lindley (2021)&lt;/a&gt;. The GVI is calculated using a Digital Surface Model (DSM), Digital Terrain Model (DTM) and Greenness Raster. GVI is written in C++ to provide fast and light weighted functionality.&lt;/p&gt;
&lt;p&gt;Go on &lt;a href=&#34;https://github.com/STBrinkmann/GVI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt; for more information.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visible Greenness Exposure Index - An example workflow for the City of Vancouver</title>
      <link>/post/visible-greenness-exposure-index-an-example-workflow-for-the-city-of-vancouver/</link>
      <pubDate>Fri, 02 Jul 2021 00:00:00 +0000</pubDate>
      <guid>/post/visible-greenness-exposure-index-an-example-workflow-for-the-city-of-vancouver/</guid>
      <description>
&lt;script src=&#34;/post/visible-greenness-exposure-index-an-example-workflow-for-the-city-of-vancouver/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In a previous posts I have &lt;a href=&#34;https://geobrinkmann.com/post/visible-greenness-exposure/&#34;&gt;introduced the Viewshed Greenness Visibility Index (VGVI)&lt;/a&gt; and demonstrated, &lt;a href=&#34;https://geobrinkmann.com/post/visibility-sensitivity-analysis/&#34;&gt;how to fine tune the parameters for calculateing the viewsheds&lt;/a&gt;. In cooperation with &lt;a href=&#34;https://www.smlabib.com/&#34;&gt;Dr. S.M. Labib&lt;/a&gt; we have build the R package &lt;a href=&#34;https://github.com/STBrinkmann/GVI&#34;&gt;GVI&lt;/a&gt;, for easily calculating VGVI’s. The VGVI expresses the proportion of visible greenness to the total visible area and is calculated using a viewshed based on a Digital Surface Model (DSM). There are other methods to compute visible greenness, for example using Google Street View panorama images instead of a DSM (&lt;a href=&#34;https://doi.org/10.1016/j.ufug.2015.06.006&#34;&gt;Li &lt;em&gt;et al.&lt;/em&gt; 2015&lt;/a&gt;). Though the method we present has some advantages, as DSM and Landuse data is already being provided for public use for many regions worldwide. Furthermore, it is very easy to not only compute the overall visible greenness, but - for example - compute visible tree-coverage or visible blue-space. Such information is important to understand how specific build environment features affect health. I will demonstrate how to calculate visible tree-coverage in the end of this post.&lt;/p&gt;
&lt;p&gt;On the &lt;a href=&#34;https://github.com/STBrinkmann/GVI&#34;&gt;GitHub website&lt;/a&gt; we have already provided examples on how to use the functions. However, a use case of this R package for researchers is to compute the VGVI for a large study area.&lt;br /&gt;
Therefore, in this post, I’d like to provide a workflow for a large area of interest, using the City of Vancouver as my study area.&lt;/p&gt;
&lt;div id=&#34;input&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Input&lt;/h2&gt;
&lt;p&gt;For computing the VGVI, we need three raster layers: the Digital Terrain Model (DEM) and Digital Surface Model (DSM) and a Greenspace Mask. The Greenspace Mask is a binary raster based on a Land Cover Classification map, where 1 = vegetation and 0 = no vegetation. I have also included bluespaces (e.g. lakes and rivers) to the greenspace mask with the value 1, since these features also seem to provide mental health benefits (&lt;a href=&#34;https://doi.org/10.1038/s41598-021-87675-0&#34;&gt;White &lt;em&gt;et al.&lt;/em&gt; 2021&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The data can be downloaded from &lt;a href=&#34;https://doi.org/10.5281/zenodo.5061256&#34;&gt;Zenodo&lt;/a&gt; and read in R like this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;### Load libraries
library(terra) # handling raster data
library(sf)    # handling shapefiles
library(GVI)   # computing the VGVI
library(dplyr) # data wrangeling

# Folder where the data has been downloaded
workdir &amp;lt;- &amp;quot;H:/Vancouver/Vancouver_Sample_Data/&amp;quot;

# Load DTM, DSM and Land Cover
dtm &amp;lt;- rast(file.path(workdir, &amp;quot;Vancouver_DTM_1m.tif&amp;quot;))
dsm &amp;lt;- rast(file.path(workdir, &amp;quot;Vancouver_DSM_1m.tif&amp;quot;))
lulc &amp;lt;- rast(file.path(workdir, &amp;quot;Vancouver_LULC_2m.tif&amp;quot;))

# Reclassify values for the binary greenspace mask

rcl_mat &amp;lt;- matrix(c(1, 6, 0,    # no vegetation
                    6, 13, 1,   # vegetation and water
                    13, 14, 0), # no vegetation
                  ncol = 3, byrow = TRUE)

greenspace &amp;lt;- classify(lulc, rcl = rcl_mat, include.lowest = TRUE)
writeRaster(greenspace, file.path(workdir, &amp;quot;Vancouver_GS_2m.tif&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Below I have provided a interactive map of a smaller region, to compare the DTM, DSM and Landuse. In &lt;a href=&#34;https://geobrinkmann.com/post/visible-greenness-exposure/#section-greenspace-mask&#34;&gt;my other post&lt;/a&gt; I have also listed all classes of the Landuse map in detail.&lt;/p&gt;
&lt;iframe frameborder=&#34;0&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34; style=&#34;display:block; width:95%; height:85vh;&#34; src=&#34;https://datageobrinkmann.be/VGVI_input.html&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;We also need the observer locations where the VGVI should be computed. In our example we could simply use all coordinates of the whole DSM. However, we can’t compute the VGVI from inside buildings, and it wouldn’t make sense to compute VGVI on water (unless you are interested in the view of stand-up paddlers). Therefore, in the next step, we only use the coordinates of useful cells from the Land Cover Classification map and convert it to a sf-point feature.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Useful Landcover Classification codes
useful_codes &amp;lt;- c(2:11, 13)

# Get XY-coordinates
xy_coords &amp;lt;- xyFromCell(lulc, which(values(lulc) %in% useful_codes)) %&amp;gt;% 
  as_tibble()

# Convert to shapefile
vancouver_2m_sf &amp;lt;- st_as_sf(xy_coords, coords = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), crs = 26910)

# Save sf
write_sf(vancouver_2m_sf, file.path(workdir, &amp;quot;Vancouver_2m_xy.gpkg&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Creating and writing the shapefile might take some time, as it contains 16.741.566 features. At this point I would recommend to restart the R session and clean the environment to free the RAM.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;vgvi&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;VGVI&lt;/h2&gt;
&lt;p&gt;Before computing the VGVI using the &lt;code&gt;vgvi_from_sf&lt;/code&gt; function from our GVI R package, I would recommend to think about some important parameters. I have partially covered this in my last &lt;a href=&#34;https://geobrinkmann.com/post/visibility-sensitivity-analysis/&#34;&gt;post&lt;/a&gt;, where I talked about the parameters &lt;em&gt;raster_res&lt;/em&gt; and &lt;em&gt;max_distance&lt;/em&gt;. So far, we have not provided recommendations for fitting the weights parameters &lt;em&gt;m&lt;/em&gt;, &lt;em&gt;b&lt;/em&gt;, and &lt;em&gt;mode&lt;/em&gt;, because we need to conduct more research in this area. However, in our study area, m = 1 and b = 3, using the exponential function (see plot below) for calculating the distance decay weights seems sufficient.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;weights_example.svg&#34; width=&#34;351&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Computing VGVI for a large area using multiple CPU cores can be RAM expensive. In addition to that, loading the complete &lt;em&gt;Vancouver_2m_xy.gpkg&lt;/em&gt; shapefile into the R session is very RAM expensive, too. Therefore, I’ll make use of a SQL statement, to load the shapefile step by step. This way, the computation is more efficient and faster. Furthermore, by saving after every step, it is very easy to continue the script at the latest position in case of an unexpected system failure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(magrittr)
library(sf)
library(terra)
library(GVI)
options(show.error.messages = T)

# Set your cores here!
cores &amp;lt;- 22

# Set workdir
workdir &amp;lt;- &amp;quot;H:/Vancouver/Vancouver_Sample_Data/&amp;quot;

# Make dir for saving the VGVI output continuously
dir.create(file.path(workdir, &amp;quot;out&amp;quot;))

# Load raster data
dtm &amp;lt;- rast(file.path(workdir, &amp;quot;Vancouver_DTM_1m.tif&amp;quot;))
dsm &amp;lt;- rast(file.path(workdir, &amp;quot;Vancouver_DSM_1m.tif&amp;quot;))
greenspace &amp;lt;- rast(file.path(workdir, &amp;quot;Vancouver_GS_2m.tif&amp;quot;))

# Sequence for the SQL statement
sql_seq &amp;lt;- as.integer(seq(1, 16741566, length.out = 201))


for(i in 2:max(seq_along(sql_seq))) {
  cat(paste0(&amp;quot;Iteration &amp;quot;, i-1, &amp;quot;/&amp;quot;, length(sql_seq)-1, &amp;quot;:\n&amp;quot;))
  
  # Load shapefile with SQL statement
  vancouver_sf &amp;lt;- st_read(
    file.path(workdir, &amp;quot;Vancouver_2m_xy.gpkg&amp;quot;),
    query = paste(&amp;quot;SELECT * FROM \&amp;quot;Vancouver_2m_xy\&amp;quot; WHERE fid BETWEEN&amp;quot;, 
                  sql_seq[i-1], &amp;quot;AND&amp;quot;, sql_seq[i]),
    quiet = TRUE)
  
  # Compute VGVI
  vancouver_vgvi &amp;lt;- vgvi_from_sf(observer = vancouver_sf,
                                 dsm_rast = dsm, 
                                 dtm_rast = dtm, 
                                 greenspace_rast = greenspace,
                                 max_distance = 550, observer_height = 1.7,
                                 raster_res = 2,
                                 m = 1, b = 3, mode = &amp;quot;exponential&amp;quot;,
                                 cores = cores, chunk_size = 10000, 
                                 folder_path = file.path(workdir, &amp;quot;out&amp;quot;),
                                 progress = TRUE)
  cat(&amp;quot;\n&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I recommend to save the code from above in a separate R script (e.g. vgvi_Vancouver_2m.R) and call this script from the console. On Linux you can do this with the command:&lt;br /&gt;
&lt;code&gt;sudo R CMD BATCH vgvi_Vancouver_2m.R &amp;amp;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This will run the R script in background and saves the output in a new file vgvi_Vancouver_2m&lt;strong&gt;.Rout&lt;/strong&gt;. You can check the progress by calling &lt;code&gt;cat vgvi_Vancouver_2m.Rout&lt;/code&gt;. In addition, I would recommend checking your CPU and RAM usage. I really like the &lt;a href=&#34;https://htop.dev/&#34;&gt;htop&lt;/a&gt; tool for this!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;vgvi-to-raster&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;VGVI to Raster&lt;/h2&gt;
&lt;p&gt;In most cases we prefer working with raster layers instead of millions of point features. Therefore, we will combine all the VGVI shapefiles from the previous step and convert them to a single raster (we will include this functionality in our package in the future). Also, I found it useful to smooth the final product by applying a moving window (focal) smoothing function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(magrittr)
library(sf)
library(terra)
library(raster)

workdir &amp;lt;- &amp;quot;H:/Vancouver/Vancouver_Sample_Data/&amp;quot;

# List all shapefiles in the out-folder
vgvi_paths &amp;lt;- list.files(file.path(workdir, &amp;quot;out&amp;quot;), 
                         full.names = TRUE, pattern = &amp;quot;.gpkg&amp;quot;)

# Load the Greenspace Mask
greenspace &amp;lt;- rast(file.path(workdir, &amp;quot;Vancouver_GS_2m.tif&amp;quot;))

pb = txtProgressBar(min = 0, max = length(vgvi_paths), initial = 0, style = 3)
for (i in seq_along(vgvi_paths)) {
  # Convert shapefile to raster, the Greenspace raster  will be 
  # used as a template for CRS and extent
  this_rast &amp;lt;- terra::rasterize(terra::vect(vgvi_paths[i]), greenspace, &amp;quot;VGVI&amp;quot;)
  names(this_rast) &amp;lt;- &amp;quot;VGVI&amp;quot;

  if (i == 1) {
    terra::writeRaster(x = this_rast, 
                       filename = file.path(workdir, &amp;quot;big_rast.tif&amp;quot;),
                       overwrite = TRUE)
  } else {
    terra::writeRaster(terra::merge(x = this_rast, 
                                    y = rast(file.path(workdir, &amp;quot;big_rast.tif&amp;quot;))),
                       filename = file.path(workdir, &amp;quot;big_rast.tif&amp;quot;),
                       overwrite = TRUE)
  }
  setTxtProgressBar(pb,i)
}

# Clean data
big_rast &amp;lt;- terra::rast(file.path(workdir, &amp;quot;big_rast.tif&amp;quot;)) %&amp;gt;%
  terra::classify(rcl = matrix(c(-Inf, 0, 0),
                               ncol = 3,
                               byrow = TRUE))

# Apply smoothing and write raster
big_rast %&amp;gt;%
  terra::focal(3, fun = median, na.rm = TRUE) %&amp;gt;%
  terra::mask(big_rast) %&amp;gt;%
  terra::writeRaster(file.path(workdir, &amp;quot;big_rast_smooth.tif&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tree-coverage-visibility&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tree-Coverage Visibility&lt;/h2&gt;
&lt;p&gt;As already mentioned in the beginning, it may be of interest to model visible tree-cover or visible blue-spaces or similar visibility assessments. Since we used a Landcover Classification map for differentiating between green vs. no-green, it is now very simple and straight forward to analyze visible tree-cover. As we did before, we need to classify coniferous and deciduous trees as 1, and the rest as 0.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rcl_mat &amp;lt;- matrix(c(1, 6, 0,    # no trees
                    6, 8, 1,    # coniferous and deciduous trees
                    8, 14, 0),  # no trees
                  ncol = 3, byrow = TRUE)

tree_cover &amp;lt;- classify(lulc, rcl = rcl_mat, include.lowest = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on this new binary tree-cover mask, the Viewshed Tree-Cover Visibility Index (VTVI) can be calculated using the scripts from above. I have excluded observer locations that are underneath trees. Below you can see the result of the VGVI and VTVI. As you can see, they have not been computed for areas with buildings or water. In the VGVI layer you can also see, that cells which are located underneath trees have an extremely high VGVI value. This is because the viewshed algorithm can’t “see” beyond those trees and returns only one single visible cell, which is green. We are currently working on ways for solving this limitation.&lt;/p&gt;
&lt;iframe frameborder=&#34;0&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34; style=&#34;display:block; width:95%; height:85vh;&#34; src=&#34;https://datageobrinkmann.be/VGVI_out.html&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;When looking at the VTVI layer, higher values are rarely achieved because it is generally harder to view trees compared to overall vegetation. The Langara Golf Course in the south and the Little Mountain park in the north are the two areas with the highest VTVI values. The residential area in the east also achieved relatively high values. This might be explained by the very large London plane trees (&lt;em&gt;Platanus × acerifolia&lt;/em&gt;), European beech trees (&lt;em&gt;Fagus sylvatica&lt;/em&gt;) and horse chestnut trees (&lt;em&gt;Aesculus hippocastanum&lt;/em&gt;) that have been planted in the side alleys.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Visible Greenness Exposure</title>
      <link>/post/visible-greenness-exposure/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      <guid>/post/visible-greenness-exposure/</guid>
      <description>
&lt;script src=&#34;/post/visible-greenness-exposure/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/post/visible-greenness-exposure/index.en_files/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/post/visible-greenness-exposure/index.en_files/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/post/visible-greenness-exposure/index.en_files/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/post/visible-greenness-exposure/index.en_files/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;p&gt;Exposure to residential greenness or green spaces such as parks or gardens are beneficial for multiple measures of health &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#section-ref-markevych2017&#34; role=&#34;doc-biblioref&#34;&gt;Markevych et al. 2017&lt;/a&gt;; &lt;a href=&#34;#section-ref-labib2020&#34; role=&#34;doc-biblioref&#34;&gt;Labib, Lindley, and Huck 2020&lt;/a&gt;)&lt;/span&gt;. Greenness and greenspace will be used as synonyms henceforth. Greenspace exposure can be categorized into three types: (a) availability, referring to the physical amount of greenspace, (b) accessibility, meaning the spatial proximity to greenspace, and (c) visibility, referring to the visual perception of greenness &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#section-ref-labib2020&#34; role=&#34;doc-biblioref&#34;&gt;Labib, Lindley, and Huck 2020&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;https://www.geography.nat.fau.eu/research/cultural-geography/wg-digital-health/#collapse_5&#34;&gt;our&lt;/a&gt; recent publication (in submission) we measured greenness taking a top-down, bird’s eye view approach using remote sensing derived &lt;a href=&#34;https://eos.com/ndvi/&#34;&gt;NDVI&lt;/a&gt;, to approximate the availability of greenness. Furthermore, we used a distance weighted road network to calculate potential neighborhood exposure models around participants place of residency, therefore also accounting for accessibility.&lt;/p&gt;
&lt;p&gt;The next step will be, to combine greenness visibility with our potential neighborhood exposure models.&lt;/p&gt;
&lt;p&gt;In this post, I will therefore demonstrate how to download and prepare all necessary files and methods needed for a visibility analysis. In the first part I demonstrate data acquisition and processing, in the second part I will explain the main functions used for the visibility analysis. My implementation of these methods is very light weighted and fast, while still maintaining high resolution. The functions presented in this post for computing a viewshed based Green Visibility Index (GVI), have also been included in the &lt;a href=&#34;https://github.com/STBrinkmann/GVI&#34;&gt;GVI&lt;/a&gt; R package.&lt;/p&gt;
&lt;div id=&#34;section-libraries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Libraries&lt;/h2&gt;
&lt;p&gt;First load all packages. If one of these packages has not been installed, use the &lt;code&gt;install.packages()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://CRAN.R-project.org/package=terra&#34;&gt;terra&lt;/a&gt; is a relatively new R package that replaces the well known &lt;a href=&#34;https://CRAN.R-project.org/package=raster&#34;&gt;raster&lt;/a&gt;. I have found &lt;code&gt;terra&lt;/code&gt; to work much faster for most tasks.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(sf)
library(ggplot2)
library(ggthemes)
library(terra)
library(lidR)
library(future)
library(data.table)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;The data is being stored in a different directory than this R project. Therefore I first need to assign my working directory.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;workdir &amp;lt;- &amp;quot;/media/sebastian/Red/Vancouver&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;section-dtm&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;DTM&lt;/h3&gt;
&lt;p&gt;First, we need to download the digital terrain model (DTM) generated from LiDAR data collected in 2013 for the City of Vancouver from the &lt;a href=&#34;https://opendata.vancouver.ca/pages/home/&#34;&gt;City of Vancouver Open Data Portal&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Download DTM as .zip
download.file(&amp;quot;https://webtransfer.vancouver.ca/opendata/TIF/DEM_2013_TIF.zip&amp;quot;,
              destfile = file.path(workdir, &amp;quot;dtm.zip&amp;quot;))

# Unzip
unzip(zipfile = file.path(workdir, &amp;quot;dtm.zip&amp;quot;), exdir = &amp;quot;Data&amp;quot;) 

# Delete .zip 
unlink(file.path(workdir, &amp;quot;dtm.zip&amp;quot;), recursive = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DTM &amp;lt;- terra::rast(file.path(workdir, &amp;quot;DEM/DEM_2013.tif&amp;quot;))

plot(DTM)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/visible-greenness-exposure/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section-lidar&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;LiDAR&lt;/h3&gt;
&lt;p&gt;Next, we will load the shapefile for the LiDAR 2013 tiles.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Lidar tiles
lidar_tiles &amp;lt;- read_sf(&amp;quot;https://opendata.vancouver.ca/explore/dataset/lidar-2013/download/?format=geojson&amp;quot;) %&amp;gt;% 
  st_transform(crs(DTM)) %&amp;gt;% 
  dplyr::select(name, lidar_url)

lidar_tiles %&amp;gt;% 
  ggplot() +
  geom_sf() + 
  theme_map()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/visible-greenness-exposure/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Each tile of this shapefile contains the tile name and a link, to download the LiDAR data. The total file size of all 168 LiDAR scenes is ~90GB. We will store them in a temporary file and calculate a DSM from the data later. I would highly recommend using parallel computation for this and to do something else while the data is being downloaded.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lidar_download &amp;lt;- function(x, tmp_dir) {
  # Download GeoTIFF as .zip
  download.file(x$lidar_url, destfile = paste0(file.path(tmp_dir, x$name), &amp;quot;.zip&amp;quot;))
  
  # Unzip
  unzip(zipfile = paste0(file.path(tmp_dir, x$name), &amp;quot;.zip&amp;quot;), 
        exdir = file.path(tmp_dir))
  
  # Delete .zip 
  unlink(paste0(file.path(tmp_dir, x$name), &amp;quot;.zip&amp;quot;), recursive = TRUE)
}

# Set number of  cores and path to tmp_dir
cores &amp;lt;- 22
tmp_dir &amp;lt;- file.path(workdir, &amp;quot;Temp&amp;quot;)

if (!dir.exists(tmp_dir)) {
  dir.create(tmp_dir)
}

# Run function
if (cores &amp;gt; 1) {
  if (Sys.info()[[&amp;quot;sysname&amp;quot;]] == &amp;quot;Windows&amp;quot;) {
    cl &amp;lt;- parallel::makeCluster(cores)
    parallel::parApply(cl, lidar_tiles, 1, FUN = lidar_download, 
                                    tmp_dir = tmp_dir)
    parallel::stopCluster(cl)
  }
  else {
    split(lidar_tiles, seq(nrow(lidar_tiles))) %&amp;gt;% 
      parallel::mclapply(FUN = lidar_download, tmp_dir = tmp_dir, 
                         mc.cores = cores, mc.preschedule = TRUE)
  }
} else {
  apply(lidar_tiles, 1, FUN = lidar_download, 
         tmp_dir = tmp_dir)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One LiDAR tile has almost no land points and the algorithm can’t process it.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;bad_LAS.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Therefore, we need to remove it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;file.remove(file.path(tmp_dir, &amp;quot;CoV_4850E_54510N.las&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we can load all LiDAR files with the &lt;code&gt;lidR&lt;/code&gt; package &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#section-ref-roussel2020&#34; role=&#34;doc-biblioref&#34;&gt;Roussel et al. 2020&lt;/a&gt;)&lt;/span&gt; and calculate the DSM using the pit-free &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#section-ref-khosravipour2014&#34; role=&#34;doc-biblioref&#34;&gt;Khosravipour et al. 2014&lt;/a&gt;)&lt;/span&gt; algorithm.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lidar_catalog &amp;lt;- lidR::readLAScatalog(tmp_dir)
crs(lidar_catalog) &amp;lt;- terra::crs(DTM)
opt_independent_files(lidar_catalog) &amp;lt;- TRUE

# Use future to calculate DSM
# Adjust number of cores with the workers parameter. This process is very RAM heavy!
plan(multisession, gc = TRUE, workers = 10)

# I would recommend to run this code from the console, to visualize the progress.
lidar_dsm &amp;lt;- grid_canopy(lidar_catalog, res = 0.5, 
                         pitfree(thresholds = c(0, 2, 5, 10, 15, 20), max_edge = c(0, 1.5)))

# Save raster and remove variables
lidar_dsm %&amp;gt;% 
  terra::rast() %&amp;gt;% 
  terra::writeRaster(filename = file.path(workdir, &amp;quot;DSM/dsm.tif&amp;quot;), format=&amp;quot;GTIFF&amp;quot;)
rm(lidar_catalog, lidar_dsm)

# Load DSM
dsm &amp;lt;- terra::rast(file.path(workdir, &amp;quot;DSM/dsm.tif&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look on the DSM. We will be using the &lt;a href=&#34;https://CRAN.R-project.org/package=rayshader&#34;&gt;rayshader&lt;/a&gt; package to generate a 2D map.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dsm_clip &amp;lt;- rast(xmin = 487200, xmax = 487800, 
                 ymin = 5455800, ymax = 5456400,
                 crs = crs(dsm), res = 0.5)

# Crop DSM and convert to matrix
elev_matrix &amp;lt;- dsm %&amp;gt;% 
  crop(dsm_clip) %&amp;gt;% 
  matrix(
    as.vector(terra::values(.)),
    nrow = ncol(.), ncol = nrow(.)
  ) %&amp;gt;% 
  t()

library(rayshader)
options(&amp;quot;cores&amp;quot; = 16)

# Calculate rayshader layers
ambmat &amp;lt;- ambient_shade(elev_matrix, multicore = TRUE)
raymat &amp;lt;- ray_shade(elev_matrix, lambert = TRUE, multicore = TRUE)


# Plot 2D
elev_matrix %&amp;gt;%
  sphere_shade(texture = &amp;quot;unicorn&amp;quot;) %&amp;gt;%
  add_shadow(raymat, max_darken = 0.5) %&amp;gt;%
  add_shadow(ambmat, max_darken = 0.1) %&amp;gt;%
  plot_map()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/visible-greenness-exposure/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are some missing values in the raster and at the right edge of the map we can see a “wall.” This is due to the fact, that power lines are being measured by LiDAR, too. Therefore we need to post-process the DSM to smooth the raster and fill empty pixels. We will apply a moving window approach. However, the DSM is too large, to apply &lt;code&gt;focal&lt;/code&gt; on the whole raster at once. Therefore we will use the &lt;code&gt;lidar_tiles&lt;/code&gt; shapefile from above, to apply smoothing and NA-value filling on subsets of the raster. To avoid edge effects, we first crop the DSM to a buffered LiDAR tile, apply the &lt;code&gt;focal&lt;/code&gt; and finally crop the processed DSM to the unbuffered LiDAR tile.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Check if processing directory exists.
delete_folder &amp;lt;- FALSE
proc_dir &amp;lt;- file.path(workdir, &amp;quot;DSM/Proc&amp;quot;)

if(!dir.exists(proc_dir)) {
  delete_folder &amp;lt;- TRUE
  dir.create(proc_dir)
}

pb = txtProgressBar(min = 0, max = nrow(lidar_tiles), initial = 0, style = 3)
for (i in 1:nrow(lidar_tiles)) {
  dsm %&amp;gt;% 
    # Crop to buffered tile
    terra::crop(sf::st_buffer(lidar_tiles[i,], 10)) %&amp;gt;% 
    # Fill NA values
    terra::focal(3, fun = median, na.only = T) %&amp;gt;%
    # Smoothing
    terra::focal(9, fun = median, na.rm = TRUE) %&amp;gt;%
    # Crop to unbuffered tile
    terra::crop(lidar_tiles[i,]) %&amp;gt;% 
    terra::writeRaster(filename = file.path(proc_dir, 
                                            paste0(&amp;quot;dsm_tile_&amp;quot;, i, &amp;quot;.tif&amp;quot;)),
                       format=&amp;quot;GTIFF&amp;quot;)
  
  setTxtProgressBar(pb, i)
}

# Merge raster tiles
filled_dsm &amp;lt;- dir(proc_dir, pattern = &amp;quot;dsm_tile_&amp;quot;, full.names = T) %&amp;gt;% 
    lapply(rast) %&amp;gt;% 
    do.call(terra::merge, .)

# Delete temp files
if (delete_folder) {
  unlink(proc_dir, recursive = TRUE)
} else {
 unlink(dir(proc_dir, pattern = &amp;quot;dsm_tile_&amp;quot;, full.names = T)) 
}

terra::writeRaster(filled_dsm, format=&amp;quot;GTIFF&amp;quot;,
                   filename = file.path(workdir, &amp;quot;DSM/dsm_filled.tif&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s look at the post-processed raster.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Crop DSM and convert to matrix
elev_matrix &amp;lt;- filled_dsm %&amp;gt;% 
  crop(dsm_clip) %&amp;gt;% 
  matrix(
    as.vector(terra::values(.)),
    nrow = ncol(.), ncol = nrow(.)
  ) %&amp;gt;% 
  t()

# Calculate rayshader layers
ambmat &amp;lt;- ambient_shade(elev_matrix, multicore = TRUE)
raymat &amp;lt;- ray_shade(elev_matrix, lambert = TRUE, multicore = TRUE)


# Plot 2D
elev_matrix %&amp;gt;%
  sphere_shade(texture = &amp;quot;unicorn&amp;quot;) %&amp;gt;%
  add_shadow(raymat, max_darken = 0.5) %&amp;gt;%
  add_shadow(ambmat, max_darken = 0.1) %&amp;gt;%
  plot_map()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/visible-greenness-exposure/index.en_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The DSM is a lot smoother than before. I have tested multiple different parameters for the smoothing-step and w=9 returned the best looking results. In the future I may apply the smoothing-step only on raster cells covered by power lines.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-visibility-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visibility Analysis&lt;/h2&gt;
&lt;p&gt;Greenspace is associated with several health benefits along multiple pathways &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#section-ref-markevych2017&#34; role=&#34;doc-biblioref&#34;&gt;Markevych et al. 2017&lt;/a&gt;; &lt;a href=&#34;#section-ref-dzhambov2020&#34; role=&#34;doc-biblioref&#34;&gt;Dzhambov et al. 2020&lt;/a&gt;; &lt;a href=&#34;#section-ref-labib2020&#34; role=&#34;doc-biblioref&#34;&gt;Labib, Lindley, and Huck 2020&lt;/a&gt;)&lt;/span&gt;. In a recent study (in submission), we analyze health benefits based on the availability and accessibility of greenspace, using a top-down, bird’s eye view, approach. Visibility describes a third type of exposure assessment and refers to the amount of greenspace that can be seen from a given point &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#section-ref-labib2020&#34; role=&#34;doc-biblioref&#34;&gt;Labib, Lindley, and Huck 2020&lt;/a&gt;)&lt;/span&gt;. Recent studies have adopted viewshed-based visibility analysis &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#section-ref-chamberlain2013&#34; role=&#34;doc-biblioref&#34;&gt;Chamberlain and Meitner 2013&lt;/a&gt;; &lt;a href=&#34;#section-ref-tabrizian2020&#34; role=&#34;doc-biblioref&#34;&gt;Tabrizian et al. 2020&lt;/a&gt;; &lt;a href=&#34;#section-ref-labib2021&#34; role=&#34;doc-biblioref&#34;&gt;Labib, Huck, and Lindley 2021&lt;/a&gt;)&lt;/span&gt;, however there still is a limited use of visibility exposure assessment in current studies &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#section-ref-labib2020&#34; role=&#34;doc-biblioref&#34;&gt;Labib, Lindley, and Huck 2020&lt;/a&gt;)&lt;/span&gt;. The following code is primarily based on the methods described by &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#section-ref-labib2021&#34; role=&#34;doc-biblioref&#34;&gt;Labib, Huck, and Lindley&lt;/a&gt; (&lt;a href=&#34;#section-ref-labib2021&#34; role=&#34;doc-biblioref&#34;&gt;2021&lt;/a&gt;)&lt;/span&gt; and their Python code of the &lt;a href=&#34;https://github.com/jonnyhuck/green-visibility-index/blob/master/gvi.py&#34;&gt;Green Visibility Index&lt;/a&gt;, and the overall process is illustrated in the figure below.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://doi.org/10.1016/j.scitotenv.2020.143050&#34;&gt;&lt;img src=&#34;gvi.jpg&#34; style=&#34;width:7.13in&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;sub&gt;&lt;em&gt;Conceptual design of greenspace visibility modelling &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#section-ref-labib2021&#34; role=&#34;doc-biblioref&#34;&gt;Labib, Huck, and Lindley 2021&lt;/a&gt;)&lt;/span&gt;.&lt;/em&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;The line of sight is being calculated from the observer to every point in the area of interest, to distinguish between visible and invisible points. To determine green and no-green points, a greenspace mask will be intersected.
To make the code presented in this post easier to understand, it has not been fully optimized. I have created the R package &lt;a href=&#34;https://github.com/STBrinkmann/GVI&#34;&gt;GVI&lt;/a&gt;, where I implemented the same functions with optimized data structures and heavy use of C++ code.&lt;/p&gt;
&lt;div id=&#34;section-rasterprofile&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Rasterprofile&lt;/h3&gt;
&lt;p&gt;To calculate the visibility of a point B from point A, we first need to access all raster cells from point A to B. The &lt;code&gt;rasterprofile&lt;/code&gt; function returns a &lt;code&gt;matrix&lt;/code&gt; with all cells from A to B, containing X- and Y-coordinates, the height and the cell-number for every cell. Surprisingly the &lt;code&gt;raster::extract&lt;/code&gt; is faster than &lt;code&gt;terra::extract&lt;/code&gt; when using a matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rasterprofile &amp;lt;- function(r, x0, y0, x1, y1, resolution){
  # Sample a raster along a straight line between two points
  # Try to match the sampling size to the raster resolution
  dx = sqrt((x0 - x1)^2 + (y0 - y1)^2)
  nsteps = 1 + round(dx / resolution)
  pointsZ &amp;lt;- cbind(x0 + (0:nsteps) * (x1 - x0) / nsteps, 
                   y0 + (0:nsteps) * (y1 - y0) / nsteps)
  
  rasterVals &amp;lt;- raster::extract(x = r, y = pointsZ, cellnumber = TRUE)
  
  pointsZ &amp;lt;- cbind(pointsZ, rasterVals[,2], rasterVals[,1])
  
  if (anyNA(pointsZ)) {
    pointsZ &amp;lt;- pointsZ[stats::complete.cases(pointsZ),,drop = FALSE]
  }
  return(pointsZ)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-line-of-sight&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Line of Sight&lt;/h3&gt;
&lt;p&gt;The observer at point A can only see point B, if no object in between point A and B blocks the view to point B. The &lt;code&gt;lineOfSight&lt;/code&gt; function evaluates visibility along all cells from A to B, by calculating tangent &lt;em&gt;⍺&lt;/em&gt; from &lt;em&gt;𝚫height&lt;/em&gt; (opposite side) and &lt;em&gt;distance traveled&lt;/em&gt; (adjacent side) and comparing it for every step. To see a point, its tangent &lt;em&gt;⍺&lt;/em&gt; must be greater than the biggest tangent &lt;em&gt;⍺&lt;/em&gt; so far.&lt;/p&gt;
&lt;p&gt;In R we would write a for loop and compare the tangent of the current point to the maximum tangent so far. Therefore this step can’t be vectorised, because the subsequent iterations depend on previous ones. Native R code is quiet “slow” for these kind of tasks. Therefore I have implemented this step in C++ using the &lt;a href=&#34;http://www.rcpp.org/&#34;&gt;Rcpp&lt;/a&gt; package.&lt;/p&gt;
&lt;pre class=&#34;cpp&#34;&gt;&lt;code&gt;#include &amp;lt;Rcpp.h&amp;gt;
using namespace Rcpp;

// [[Rcpp::export]]
NumericVector isVisibleC(NumericVector x) {
  int n = x.size();
  NumericVector out(n);
  out[0] = 1;
  
  double max_tangent = -9999;
  
  for(int i = 1; i &amp;lt; n; ++i) {
    double this_tangent = x[i];
    
    if (this_tangent &amp;gt; max_tangent) {
      max_tangent = this_tangent;
      out[i] = 1;
    } else {
      out[i] = -1;
    }
  }
  return out;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;lineOfSight&lt;/code&gt; function returns a &lt;code&gt;data.table&lt;/code&gt; containing the cell number and corresponding visibility of all points from A to B. Visible cells have a value of 1 and non visible cells -1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lineOfSight &amp;lt;- function(xy1, x0, y0, height0, resolution, dsm_data) {
  # Get start XY from input
  x1 &amp;lt;- xy1[1]
  y1 &amp;lt;- xy1[2]
  
  # Get the pixels in the line
  pixels &amp;lt;- rasterprofile(r = dsm_data, x0 = x0, y0 = y0, x1 = x1, y1 = y1, 
                          resolution = resolution)
  
  # Distance traveled so far
  distance_traveled = sqrt((y0 - pixels[,2])^2 + (x0 - pixels[,1])^2)
    
  # Calculate tangent from delta height (opposite side) and distance traveled (adjacent side)
  tangents &amp;lt;- (pixels[,3] - height0) / (distance_traveled * resolution)
  
  # Is visible? Current tangent must be greater than max. tangent
  visibility &amp;lt;- isVisibleC(tangents)
  
  # Return cellnumber and visibility-value
  data.table::as.data.table(cbind(pixels[,4], visibility))
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-viewshed&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Viewshed&lt;/h3&gt;
&lt;p&gt;Finally, the visibility of all points withing a certain buffer around point A can be calculated, using the &lt;code&gt;lineOfSight&lt;/code&gt; function. The &lt;code&gt;viewshed&lt;/code&gt; function returns a circular raster (start point + max_distance-buffer) where values of 1 indicate visible points and -1 non-visible points. To calculate visibility for all points in the raster, we only need to calculate the line of sight from the center to all boundary points of the circle and store the information of each point in between.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;viewshed &amp;lt;- function(sf_start, max_distance, dsm_data, dtm_data, resolution, 
                     observer_height, cores = 1, plot = FALSE) {
  
  # AOI
  this_aoi &amp;lt;- sf_start %&amp;gt;% 
    sf::st_buffer(max_distance)
  
  # Coordinates of start point
  x0 &amp;lt;- sf::st_coordinates(sf_start)[1]
  y0 &amp;lt;- sf::st_coordinates(sf_start)[2]
  
  # Observer height
  height0 &amp;lt;- as.numeric(terra::extract(dtm_data, cbind(x0, y0))) + observer_height
  
  # If the resolution parameter differs from the input-DSM resolution,
  # resample the DSM to the lower resolution.
  # Also, convert dsm_data_masked to &amp;quot;Raster&amp;quot; object, for faster internal calculation.
  if ((res(dsm_data)[1] != resolution) &amp;amp; (resolution &amp;gt;= 1)) {
    dsm_data_masked &amp;lt;- terra::crop(dsm_data, this_aoi) %&amp;gt;% 
      terra::aggregate(fact = resolution/terra::res(.)) %&amp;gt;% 
      terra::mask(terra::vect(this_aoi))
    
    output &amp;lt;- terra::setValues(dsm_data_masked, 0) %&amp;gt;%
      terra::mask(dsm_data_masked)
    
    dsm_data_masked &amp;lt;- as(dsm_data_masked, &amp;quot;Raster&amp;quot;)
  } else {
    dsm_data_masked &amp;lt;- terra::crop(dsm_data, this_aoi) %&amp;gt;% 
      terra::mask(terra::vect(this_aoi))
    
    output &amp;lt;- terra::setValues(dsm_data_masked, 0) %&amp;gt;% 
      terra::mask(dsm_data_masked)
    
    dsm_data_masked &amp;lt;- as(dsm_data_masked, &amp;quot;Raster&amp;quot;)
  }
  
  
  # Calculate boundaries of output raster (boundaries are adjacent to NA values)
  output_boundaries &amp;lt;- terra::expand(output, resolution*2) %&amp;gt;% 
    terra::boundaries()
  
  # Get coordinates of boundaries cells and convert to list
  xy_stop &amp;lt;- terra::xyFromCell(output_boundaries, which(terra::values(output_boundaries) == 1)) %&amp;gt;% 
    split(seq(nrow(.)))
  
  # Apply lineOfSight function on every point in xy_stop
  if (cores &amp;gt; 1) {
    if (Sys.info()[[&amp;quot;sysname&amp;quot;]] == &amp;quot;Windows&amp;quot;) {
      cl &amp;lt;- parallel::makeCluster(cores)
      parallel::clusterExport(cl, &amp;quot;rasterprofile&amp;quot;)
      parallel::clusterEvalQ(cl, library(&amp;quot;dplyr&amp;quot;))
      this_LoS &amp;lt;- parallel::parLapply(cl, xy_stop, fun = lineOfSight, 
                                     x0 = x0, y0 = y0,
                                     height0 = height0, resolution = resolution, 
                                     dsm_data = dsm_data_masked)
      parallel::stopCluster(cl)
    }
    else {
      this_LoS &amp;lt;- parallel::mclapply(xy_stop, lineOfSight, 
                                     x0 = x0, y0 = y0,
                                     height0 = height0, resolution = resolution, 
                                     dsm_data = dsm_data_masked, 
                                     mc.cores = cores, mc.preschedule = TRUE)
    }
  } else {
    this_LoS &amp;lt;- lapply(xy_stop, FUN = lineOfSight, 
                       x0 = x0, y0 = y0,
                       height0 = height0, resolution = resolution, 
                       dsm_data = dsm_data_masked)
  }
  
  # Bind list
  this_LoS &amp;lt;- data.table::rbindlist(this_LoS)
  
  # Copy result of lapply to the output raster 
  output[this_LoS[[1]]] &amp;lt;- this_LoS[[2]]
  
  # Compare DSM with Visibilty
  if (plot) {
    par(mfrow=c(1,2))
    plot(dsm_data_masked); points(x0, y0, col = &amp;quot;red&amp;quot;, pch = 20, cex = 2)
    plot(output, legend = F); points(x0, y0, col = &amp;quot;red&amp;quot;, pch = 20, cex = 2)
    par(mfrow=c(1,1))
  }
  return(output)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The animation below illustrates, the functionality of the &lt;code&gt;viewshed&lt;/code&gt; function. Starting with a raster of unknown visibility (yellow), we iterative call the &lt;code&gt;lineOfSight&lt;/code&gt; function and set the status of each raster cell to visible (green) or no-visible (white).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;LoS.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section-examples&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Examples&lt;/h3&gt;
&lt;p&gt;We need to create a start point to compare the effect of different resolutions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Disable progress bar for terra::aggregate
terra::terraOptions(progress = 0)

sf_start &amp;lt;- sfheaders::sf_point(c(487616.2, 5455970)) %&amp;gt;% 
    st_sf(crs = st_crs(26910))&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;section-resolution-0.5m&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;1. Resolution = 0.5m&lt;/h4&gt;
&lt;p&gt;Output-Raster-Cells: 1 440 000&lt;br /&gt;
Runtime: 0.85 seconds (cores=1: 1.80 seconds)&lt;br /&gt;
Total visibility: 11.9%&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;viewshed_1 &amp;lt;- viewshed(sf_start = sf_start, max_distance = 300,
                       dsm_data = filled_dsm, dtm_data = DTM, 
                       resolution = 0.5, observer_height = 1.8, 
                       cores = 10, plot = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/visible-greenness-exposure/index.en_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;1536&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section-resolution-1m&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;2. Resolution = 1m&lt;/h4&gt;
&lt;p&gt;Output-Raster-Cells: 360 000&lt;br /&gt;
Runtime: 0.45 seconds (cores=1: 0.75 seconds)&lt;br /&gt;
Total visibility: 12.4%&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;viewshed_2 &amp;lt;- viewshed(sf_start = sf_start, max_distance = 300,
                       dsm_data = filled_dsm, dtm_data = DTM, 
                       resolution = 1, observer_height = 1.8, 
                       cores = 10, plot = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/visible-greenness-exposure/index.en_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;1536&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section-resolution-2m&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;3. Resolution = 2m&lt;/h4&gt;
&lt;p&gt;Output-Raster-Cells: 90 000&lt;br /&gt;
Runtime: 0.35 seconds (cores=1: 0.40 seconds)&lt;br /&gt;
Total visibility: 12.8%&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;viewshed_3 &amp;lt;- viewshed(sf_start = sf_start, max_distance = 300,
                       dsm_data = filled_dsm, dtm_data = DTM, 
                       resolution = 2, observer_height = 1.8, 
                       cores = 5, plot = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/visible-greenness-exposure/index.en_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;1536&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section-resolution-5m&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;4. Resolution = 5m&lt;/h4&gt;
&lt;p&gt;Output-Raster-Cells: 14 400&lt;br /&gt;
Runtime: 0.22 seconds (cores=1: 0.18 seconds)&lt;br /&gt;
Total visibility: 14.6%&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;viewshed_4 &amp;lt;- viewshed(sf_start = sf_start, max_distance = 300,
                       dsm_data = filled_dsm, dtm_data = DTM, 
                       resolution = 5, observer_height = 1.8, 
                       cores = 2, plot = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/visible-greenness-exposure/index.en_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;1536&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-network-visible-greenspace&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Network Visible Greenspace&lt;/h2&gt;
&lt;p&gt;One practical application of the viewshed algorithm is, to calculate the visible neighborhood greenness of an observer, by analyzing visible greenness along roads and paths in the neighborhood.&lt;/p&gt;
&lt;div id=&#34;section-greenspace-mask&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Greenspace Mask&lt;/h3&gt;
&lt;p&gt;To determine the level of greenness for the visible cells in a viewshed, we need to define green and no-green pixels. For this purpose we will be using the &lt;a href=&#34;http://www.metrovancouver.org/data/Data/LandCoverClassification-2m/LCC2014_2m_LiDAR_gdb.zip&#34;&gt;Vancouver Land Cover Classification 2014 - 2m LiDAR (Raster)&lt;/a&gt;. This data can be opened using ArcGIS and exported as TIFF for further analysis. From the documentation we can read the class values as follows:&lt;/p&gt;
&lt;table style=&#34;width:90%; font-family: &amp;quot;Arial Narrow&amp;quot;, &amp;quot;Source Sans Pro&amp;quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;&#34; class=&#34; lightable-classic lightable-striped&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;font-weight: bold;&#34;&gt;
Value
&lt;/th&gt;
&lt;th style=&#34;text-align:center;font-weight: bold;&#34;&gt;
Level 1
&lt;/th&gt;
&lt;th style=&#34;text-align:center;font-weight: bold;&#34;&gt;
Level 2
&lt;/th&gt;
&lt;th style=&#34;text-align:center;font-weight: bold;&#34;&gt;
Level 3
&lt;/th&gt;
&lt;th style=&#34;text-align:left;font-weight: bold;&#34;&gt;
Criteria
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Built-up
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Buildings
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Identified using shape/size, shadow cast, height, relative canopy height, texture.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Paved
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Everything from sidewalks and alleys to highways.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Other Built
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not concrete/asphalt built surfaces or building roofs. Sports surfaces (artificial turf and running tacks), possibly transit or rail areas, other impervious surfaces, etc.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Bare
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Barren
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Beaches, alpine rock, shoreline rock, etc. Lack of vegetation. Likely not soil (colour/context suggests no organic matter and/or imperviousness). Also quarries, gravel pits, dirt roads.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Soil
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Agricultural soils (could be light or dark), cleared/open areas where darker colours indicate organic matter present (as compared to, e.g. sand), potentially riverine/alluvial deposits.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Vegetation
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Tree canopy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Coniferous
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Predominantly coniferous (&amp;gt;75%)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Deciduous
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Predominantly deciduous (&amp;gt;75%)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Shrub
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Woody, leafy, and generally rough-textured vegetation shorter than trees (approx. &amp;lt;3-4m), taller than grass.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Grass-herb
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Modified Grass-herb
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Crops, golf course greens, city park grass, lawns, etc.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Natural Grass-herb
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Alpine meadows, near-shore grass areas, bog/wetland areas.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Non-photosynthetic vegetation
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Dead grass, drought stressed vegetation, could include log
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Water
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lakes, rivers, inlets, irrigation channels, retention ponds, pools, etc.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Shadow
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Dark pixels with v/ low reflectance values. Image features not easily visible. Compare w/ RapidEye image for shadow
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Clouds/Ice
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Very bright pixels, that are not high-reflectance features from built-up areas.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For demonstration purpose I will use all vegetation classes as one criteria (green vs. no-green).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load LandCover
landCover &amp;lt;- rast(file.path(workdir, &amp;quot;LCC2014_2m_LiDAR1.tif&amp;quot;))

# Select Vegetation
greenspace &amp;lt;- landCover %in% c(6:10); invisible(gc())

# Plot to compare LandCover and vegetation mask
par(mfrow = c(1,2))
landCover %&amp;gt;% 
  crop(dsm_clip) %&amp;gt;% 
  plot(legend = FALSE)

points(st_coordinates(sf_start)[1], st_coordinates(sf_start)[2], 
       col = &amp;quot;blue&amp;quot;, cex = 3, pch = 20)

greenspace %&amp;gt;% 
  crop(dsm_clip) %&amp;gt;% 
  plot(legend = FALSE)

points(st_coordinates(sf_start)[1], st_coordinates(sf_start)[2], 
       col = &amp;quot;blue&amp;quot;, cex = 3, pch = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/visible-greenness-exposure/index.en_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;1536&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section-green-visibility-index&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Green Visibility Index&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;gvi&lt;/code&gt; (Green Visibility Index; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#section-ref-labib2021&#34; role=&#34;doc-biblioref&#34;&gt;Labib, Huck, and Lindley 2021&lt;/a&gt;)&lt;/span&gt;) function returns the proportion of visible greenspace to total visibility. The values range between 0 and 1, where 0 = no green cells are visible, and 1 = all of the visible cells are green. Applying the &lt;code&gt;visibleGreen&lt;/code&gt; function on the &lt;code&gt;viewshed_1&lt;/code&gt; object calculated above returns 0.91, meaning that 91% of the visible area is vegetated.&lt;br /&gt;
In the original paper of &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#section-ref-labib2021&#34; role=&#34;doc-biblioref&#34;&gt;Labib, Huck, and Lindley&lt;/a&gt; (&lt;a href=&#34;#section-ref-labib2021&#34; role=&#34;doc-biblioref&#34;&gt;2021&lt;/a&gt;)&lt;/span&gt; the authors also applied a distance decay function, to account for the reducing visual prominence of an object in space with increasing distance from the observer. However, I will address this issue in another post about distance decay models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gvi &amp;lt;- function(viewshed, greenspace) {
  # Get XY coordinates that are visible
  xy &amp;lt;- viewshed %&amp;gt;% 
    terra::xyFromCell(which(viewshed[] == 1))

  # Intersect XY with greenspace mask
  output &amp;lt;- greenspace[terra::cellFromXY(greenspace, xy)] %&amp;gt;% 
    unlist(use.names = FALSE)

  # Proportion of visible green
  return(sum(output == 1) / length(output))
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-network-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Network Analysis&lt;/h3&gt;
&lt;p&gt;We will use the &lt;code&gt;DRIGLUCoSE&lt;/code&gt; R package from our recent publication to calculate a road network, and finally asses visible greenspace along the network. For a detailed explanation of the &lt;code&gt;DRIGLUCoSE&lt;/code&gt; package see the &lt;a href=&#34;https://github.com/STBrinkmann/DRIGLUCoSE&#34;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Download and process road network from OSM data
aoi.osm &amp;lt;- DRIGLUCoSE::osm_roads(x = sf_start, dist = 10, speed = 75)

# Calculate isodistances
aoi.isodistances &amp;lt;- DRIGLUCoSE::isodistances(x = sf_start %&amp;gt;% mutate(tag = 1),
                                             tag = &amp;quot;tag&amp;quot;, road_network = aoi.osm, 
                                             speed = 75, 
                                             isochrones_seq = seq(1, 10, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the figure below the isodistances are being illustrated. The red point represents the starting point. We will calculate visible greenspace proportion every 10m.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/visible-greenness-exposure/index.en_files/figure-html/unnamed-chunk-28-1.svg&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To evaluate network visibility, we will write a new function &lt;code&gt;networkVisibleGreenspace&lt;/code&gt; to combine all previous steps to a single point along the network.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;networkVisibleGreenspace &amp;lt;- function(x, isodistance, greenspace,
                                     dsm_data, dtm_data, 
                                     resolution, max_distance, observer_height, 
                                     cores, plot = FALSE) {
  
  # 1. Calculate viewshed
  this_viewshed &amp;lt;- viewshed(sf_start = x, max_distance = max_distance,
                            dsm_data = dsm_data, dtm_data = dtm_data, 
                            resolution = resolution, 
                            observer_height = observer_height, 
                            cores = cores, plot = plot)
  
  # 2. Proportion of visible greenspace of total visibility (GVI)
  this_gvi &amp;lt;- gvi(viewshed = this_viewshed, greenspace = greenspace)
  
  # 3. Get time value of x from isodistance
  return(dplyr::tibble(time = isodistance[sf::st_nearest_feature(x, isodistance),]$time, 
                       GVI = this_gvi,
                       X = as.numeric(st_coordinates(x)[1]),
                       Y = as.numeric(st_coordinates(x)[2])))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can use the &lt;code&gt;st_line_sample&lt;/code&gt; function to sample points along the isodistance object. In the viewshed examples above we have seen, that for &lt;code&gt;resolution = 2&lt;/code&gt; the computation time hardly differs if we set &lt;code&gt;cores = 1&lt;/code&gt;. Therefore I use &lt;code&gt;cores = 1&lt;/code&gt; in the &lt;code&gt;networkVisibleGreenspace&lt;/code&gt; and call it from the &lt;code&gt;mclapply&lt;/code&gt; with parallel processing.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Sample points on the isodistance for every 25m 
all_points &amp;lt;- aoi.isodistances %&amp;gt;% 
  sf::st_union() %&amp;gt;% 
  sf::st_cast(&amp;quot;LINESTRING&amp;quot;) %&amp;gt;% 
  sf::st_line_sample(density = 1/25) %&amp;gt;% 
  sf::st_cast(&amp;quot;POINT&amp;quot;) %&amp;gt;% 
  sf::st_as_sf()

# Calculate network visibilty 
output &amp;lt;- all_points %&amp;gt;% 
  split(seq(nrow(.))) %&amp;gt;% 
  parallel::mclapply(networkVisibleGreenspace,
                     isodistance = aoi.isodistances, greenspace = greenspace,
                     dsm_data = filled_dsm, dtm_data = DTM, resolution = 2, 
                     max_distance = 300, observer_height = 1.8, cores = 1, 
                     plot = FALSE, mc.cores = 22, mc.preschedule = TRUE) %&amp;gt;% 
  do.call(rbind, .)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-results&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;The results of the &lt;code&gt;networkVisibilityGreenspace&lt;/code&gt; is illustrated in the figure below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/visible-greenness-exposure/index.en_files/figure-html/unnamed-chunk-31-1.svg&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To evaluate the mean GVI for the observer in the center, we need to summarize all measurements from the previous steps. I simply take the mean of all values, but one could also apply a linear or logistic weights function, such that the influence of a variable decreases with increasing distance, as demonstrated in our recent publication.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;round(mean(output$GVI), 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A mean value of 0.5 indicates, that 50% of the visible area along the network is vegetated.&lt;/p&gt;
&lt;p&gt;One big limitation of the viewshed algorithm is, that it fails to calculate eye-level visibility if the observer is underneath a tree. This is because we use a LiDAR derived DSM and calculate visibility based on the height of pixels along the lines of sight.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/visible-greenness-exposure/index.en_files/figure-html/unnamed-chunk-33-1.svg&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The histogram above shows, that there are a lot of points with GVI = 1. I have plotted the DSM and the GVI points along the route network in QGIS.&lt;img src=&#34;GVI_bad.png&#34; style=&#34;width:7.13in&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The dark-green points are located underneath trees. Therefore, the viewshed algorithm can’t “see” beyond those trees and returns only one single visible cell, which is green. The proportion of green pixels to all visible pixels is therefore 1.&lt;/p&gt;
&lt;p&gt;As already mentioned, applying a distance function might simulate the potential activity space better, since a person will most likely use the road/path in front of his/her place of residence more often than the road 10 minutes away. I will talk about this issue in a different post and provide a solution using the &lt;a href=&#34;https://cran.r-project.org/web/packages/mosaic/index.html&#34;&gt;mosaic&lt;/a&gt; R package.&lt;/p&gt;
&lt;p&gt;However, we can see a high diversity of GVI values in the example above, in that the northern half has higher visible greenness. Therefore, future research may also incorporate &lt;em&gt;actual&lt;/em&gt; activity space measurements instead of &lt;em&gt;potential&lt;/em&gt; activity space models, to further analyze where (and why) participants spend time and thus improve the understanding of greenspace related health effects.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Data acquisition and processing with &lt;code&gt;lidR&lt;/code&gt; and &lt;code&gt;terra&lt;/code&gt; is simple and fast using R as the only tool. The implementation of a parallel viewshed algorithm has proven to be very light-weighted and fast. Using a lower resolution significantly reduces model runtime. However, even at highest resolution, the runtime is acceptable. The effect of multiprocessing is significant only with high resolution or very large values of &lt;code&gt;max_distance&lt;/code&gt;. Using this algorithm in a large scale study at high resolution appears to be practical. Compared to model 1, model 4 has an increase in visible area from 11.9% to 14.6%. The results of the other models are closer to model 1. In my opinion the trade-off between loss of accuracy for an increase in speed is acceptable down to 2m. But reducing the resolution to 5m or even more might only be worth it, if a lot of observations need to be calculated or/and for large values of &lt;em&gt;max_distance&lt;/em&gt;, since the computation time hardly differs from 2m resolution. I would suggest comparing a few points with 0.5m, 1m, 2m and 5m resolution.&lt;br /&gt;
One mayor limitation of this method is, that it fails to calculate eye-level visibility, if the observer is located underneath a tree.&lt;br /&gt;
A simple implementation of the viewshed analysis into a route network analysis served as a practical example for researching greenspace exposure.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section-references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;section-refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;&gt;
&lt;div id=&#34;section-ref-chamberlain2013&#34; class=&#34;csl-entry&#34;&gt;
Chamberlain, Brent C., and Michael J. Meitner. 2013. &lt;span&gt;“A Route-Based Visibility Analysis for Landscape Management.”&lt;/span&gt; &lt;em&gt;Landscape and Urban Planning&lt;/em&gt; 111 (March): 13–24. &lt;a href=&#34;https://doi.org/10.1016/j.landurbplan.2012.12.004&#34;&gt;https://doi.org/10.1016/j.landurbplan.2012.12.004&lt;/a&gt;.
&lt;/div&gt;
&lt;div id=&#34;section-ref-dzhambov2020&#34; class=&#34;csl-entry&#34;&gt;
Dzhambov, Angel M., Matthew H.E.M. Browning, Iana Markevych, Terry Hartig, and Peter Lercher. 2020. &lt;span&gt;“Analytical Approaches to Testing Pathways Linking Greenspace to Health: A Scoping Review of the Empirical Literature.”&lt;/span&gt; &lt;em&gt;Environmental Research&lt;/em&gt; 186 (July): 109613. &lt;a href=&#34;https://doi.org/10.1016/j.envres.2020.109613&#34;&gt;https://doi.org/10.1016/j.envres.2020.109613&lt;/a&gt;.
&lt;/div&gt;
&lt;div id=&#34;section-ref-khosravipour2014&#34; class=&#34;csl-entry&#34;&gt;
Khosravipour, Anahita, Andrew K. Skidmore, Martin Isenburg, Tiejun Wang, and Yousif A. Hussin. 2014. &lt;span&gt;“Generating Pit-Free Canopy Height Models from Airborne Lidar.”&lt;/span&gt; &lt;em&gt;Photogrammetric Engineering &amp;amp; Remote Sensing&lt;/em&gt; 80 (9): 863–72. &lt;a href=&#34;https://doi.org/10.14358/pers.80.9.863&#34;&gt;https://doi.org/10.14358/pers.80.9.863&lt;/a&gt;.
&lt;/div&gt;
&lt;div id=&#34;section-ref-labib2021&#34; class=&#34;csl-entry&#34;&gt;
Labib, S.M., Jonny J. Huck, and Sarah Lindley. 2021. &lt;span&gt;“Modelling and Mapping Eye-Level Greenness Visibility Exposure Using Multi-Source Data at High Spatial Resolutions.”&lt;/span&gt; &lt;em&gt;Science of The Total Environment&lt;/em&gt; 755 (February): 143050. &lt;a href=&#34;https://doi.org/10.1016/j.scitotenv.2020.143050&#34;&gt;https://doi.org/10.1016/j.scitotenv.2020.143050&lt;/a&gt;.
&lt;/div&gt;
&lt;div id=&#34;section-ref-labib2020&#34; class=&#34;csl-entry&#34;&gt;
Labib, S.M., Sarah Lindley, and Jonny J. Huck. 2020. &lt;span&gt;“Spatial Dimensions of the Influence of Urban Green-Blue Spaces on Human Health: A Systematic Review.”&lt;/span&gt; &lt;em&gt;Environmental Research&lt;/em&gt; 180 (January): 108869. &lt;a href=&#34;https://doi.org/10.1016/j.envres.2019.108869&#34;&gt;https://doi.org/10.1016/j.envres.2019.108869&lt;/a&gt;.
&lt;/div&gt;
&lt;div id=&#34;section-ref-markevych2017&#34; class=&#34;csl-entry&#34;&gt;
Markevych, Iana, Julia Schoierer, Terry Hartig, Alexandra Chudnovsky, Perry Hystad, Angel M. Dzhambov, Sjerp de Vries, et al. 2017. &lt;span&gt;“Exploring Pathways Linking Greenspace to Health: Theoretical and Methodological Guidance.”&lt;/span&gt; &lt;em&gt;Environmental Research&lt;/em&gt; 158 (October): 301–17. &lt;a href=&#34;https://doi.org/10.1016/j.envres.2017.06.028&#34;&gt;https://doi.org/10.1016/j.envres.2017.06.028&lt;/a&gt;.
&lt;/div&gt;
&lt;div id=&#34;section-ref-roussel2020&#34; class=&#34;csl-entry&#34;&gt;
Roussel, Jean-Romain, David Auty, Nicholas C. Coops, Piotr Tompalski, Tristan R.H. Goodbody, Andrew Sánchez Meador, Jean-François Bourdon, Florian de Boissieu, and Alexis Achim. 2020. &lt;span&gt;“lidR: An R Package for Analysis of Airborne Laser Scanning (ALS) Data.”&lt;/span&gt; &lt;em&gt;Remote Sensing of Environment&lt;/em&gt; 251 (December): 112061. &lt;a href=&#34;https://doi.org/10.1016/j.rse.2020.112061&#34;&gt;https://doi.org/10.1016/j.rse.2020.112061&lt;/a&gt;.
&lt;/div&gt;
&lt;div id=&#34;section-ref-tabrizian2020&#34; class=&#34;csl-entry&#34;&gt;
Tabrizian, Payam, Perver K. Baran, Derek Van Berkel, Helena Mitasova, and Ross Meentemeyer. 2020. &lt;span&gt;“Modeling Restorative Potential of Urban Environments by Coupling Viewscape Analysis of Lidar Data with Experiments in Immersive Virtual Environments.”&lt;/span&gt; &lt;em&gt;Landscape and Urban Planning&lt;/em&gt; 195 (March): 103704. &lt;a href=&#34;https://doi.org/10.1016/j.landurbplan.2019.103704&#34;&gt;https://doi.org/10.1016/j.landurbplan.2019.103704&lt;/a&gt;.
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>

[{"authors":null,"categories":null,"content":"I am a Physical Geographer at FAU Nürnberg-Erlangen. In our research group I work as an Data Analyst and focus on machine learning, and the intersection of natural environment and human behaviour by developing novel algorithms.\nIn my spare time, I practise Aikido and enjoy working on private coding projects and traveling the world with my backpack.\n","date":1625443200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1625476451,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/sebastian-brinkmann/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sebastian-brinkmann/","section":"authors","summary":"I am a Physical Geographer at FAU Nürnberg-Erlangen. In our research group I work as an Data Analyst and focus on machine learning, and the intersection of natural environment and human behaviour by developing novel algorithms.","tags":null,"title":"Sebastian Brinkmann","type":"authors"},{"authors":[],"categories":[],"content":"\r\rA common task in the field of geostatistics is interpolation. According to the first law of Geography, “Everything is related to everything else. But near things are more related than distant things.” (Tobler 1970). We can make use of this to interpolate values over a spatial region from a finite set of observations. There are already a number of great sources that describe geospatial interpolation methods (GISGeography 2016; Hartmann, Krois, and Waske 2018; Dunnington 2019; Wilke 2020). So in this post I don’t want to explain these methods again, but instead give a practical example on how to implement Inverse Distance Weighting (IDW) in C++ with Rcpp. I will explain the Rcpp code step by step, the finished result is available in the GVI R package on GitHub.\nGISGeography (2016) provides an excellent explanation of the maths behind IDW. In short, the interpolated value of any location is based on the values of known locations, assuming closer values are more related than further values.\n\\[\rz = \\frac{\\sum_{i}^{n}\\frac{z_i}{{d_i}^\\beta}}{\\sum_{i}^{n}\\frac{1}{{d_i}^\\beta}}\r\\]\nwhere \\(z\\) is the value to be interpolated, \\(n\\) the number of surrounding known locations, and \\(z_i\\) and \\(d_i\\) their corresponding value and distance, respectively. \\(\\beta\\) describes the distance power, that determines the degree to which nearer points are preferred over more distant points.\nBelow is a small example visualized using the rayshader R package:\n\r\rDistance\rValue\r\r\r\r300\r12\r\r800\r8\r\r850\r10\r\r1300\r9\r\r\r\rUsing the equation we can manually calculate the value \\(z\\) for the point in the middle with \\(\\beta = 2\\) as:\n\\(z = (\\frac{12}{300^2} + \\frac{8}{800^2} + \\frac{10}{850^2} + \\frac{9}{1300^2}) / (\\frac{1}{300^2} + \\frac{1}{800^2} + \\frac{1}{850^2} + \\frac{1}{1300^2})\\approx 11.3\\)\nComputing IDW with Rcpp\rData\rFirst of all we need some data to interpolate. For that we will follow along the example of the FU-Berlin (Hartmann, Krois, and Waske 2018) and use weather station data provided by the Deutscher Wetterdienst (DWD) (German Weather Service).\nlibrary(dplyr)\rlibrary(sf)\r# Retrieve Federal States by the the getData() function from the raster package\reast_germany \u0026lt;- c(\u0026#39;Sachsen\u0026#39;, \u0026#39;Sachsen-Anhalt\u0026#39;, \u0026#39;Berlin\u0026#39;,\r\u0026#39;Mecklenburg-Vorpommern\u0026#39;,\u0026#39;Brandenburg\u0026#39;, \u0026#39;Thüringen\u0026#39;)\raoi \u0026lt;- raster::getData(country = \u0026quot;Germany\u0026quot;, level = 1) %\u0026gt;%\rst_as_sf() %\u0026gt;% filter(NAME_1 %in% east_germany) %\u0026gt;% st_transform(3035) %\u0026gt;%\rst_union()\r# Download DWD data\rdwd \u0026lt;- read.csv2(\u0026quot;https://userpage.fu-berlin.de/soga/300/30100_data_sets/DWD.csv\u0026quot;,\rstringsAsFactors = FALSE) %\u0026gt;% as_tibble() %\u0026gt;% select(\u0026#39;LAT\u0026#39;,\u0026#39;LON\u0026#39;, \u0026quot;MEAN.ANNUAL.RAINFALL\u0026quot;, \u0026quot;ALTITUDE\u0026quot;) %\u0026gt;%\rrename(rain = \u0026quot;MEAN.ANNUAL.RAINFALL\u0026quot;) %\u0026gt;% na.omit()\r# Convert to SF and transform to ETRS89/LAEA Europe\rdwd.sf \u0026lt;- st_as_sf(dwd, coords = c(\u0026quot;LON\u0026quot;,\u0026quot;LAT\u0026quot;), crs = 4326) %\u0026gt;% st_transform(3035) %\u0026gt;% st_intersection(aoi)\rFor the Rcpp algorithm, we need to convert the shapefile to a raster first and extract the raster values.\nlibrary(raster)\rdwd.rast \u0026lt;- raster(xmn = st_bbox(dwd.sf)[1],\rxmx = st_bbox(dwd.sf)[3],\rymn = st_bbox(dwd.sf)[2],\rymx = st_bbox(dwd.sf)[4],\rcrs = st_crs(dwd.sf)$proj4string,\rresolution = 10000) %\u0026gt;% rasterize(dwd.sf, ., \u0026quot;rain\u0026quot;, background = NA)\rdwd.rast_values \u0026lt;- getValues(dwd.rast)\r\rRcpp code\rWe use the S4 structure of raster objects to read basic raster information (e.g. resolution, nrow, …) from the input raster. For that I’ll include the RasterInfo structure that you can find here. The Rcpp implementation of the IDW algorithm has the following general structure:\n#include \u0026lt;Rcpp.h\u0026gt;\r#include \u0026quot;rsinfo.h\u0026quot;\rusing namespace Rcpp;\r// [[Rcpp::export]]\rNumericVector IDW_Rcpp(S4 \u0026amp;rast, const NumericVector \u0026amp;x,\rconst int n, const double b, const double radius)\r{\r// Basic raster information\rRasterInfo rast_info(rast);\r// Convert radius to pixel\rconst int r_pxl = (int)(radius/rast_info.res);\r// Output\rNumericVector out(x.size(), NA_REAL);\r// Main loop: Loop over all values of the raster x\rfor(int j = 0; j \u0026lt; x.size(); j++){\r// 1. Convert j to row/col and X/Y coordinates\r// 2. Calculate distance to all cells and store their values\r// 3. Sort by distance and select top n\r// 4. Compute IDW\r}\rreturn out;\r}\rBelow I will explain all four sections in detail, you can find the final source code on GitHub. Also, if you would like to support multithreading, it is really simple using OpenMP. We’ll come back to that later.\n1. Convert j to row/col and X/Y coordinates\rWe can use simple math to obtain the row/col and X/Y coordinates from the current cell \\(j\\).\n// row col from cell\rconst int row_j = j / rast_info.ncol;\rconst int col_j = j - (row_j * rast_info.ncol);\r// XY from cell\rconst double y_j = rast_info.ymax - (row_j + 0.5) * rast_info.res;\rconst double x_j = rast_info.xmin + (col_j + 0.5) * rast_info.res;\r\r2. Calculate distance to all cells and store their values\rTo calculate the distance to the current cell \\(j\\) and the corresponding value we need to iterate over all cells that are within the radius. For that we take the row (or column) $row_j$ and loop over all rows (or columns) \\(row_i\\), where \\(row_j-radius \u0026lt;= row_i \u0026lt;= row_j+radius\\).\nAgain, the cell \\(i\\) and X/Y coordinates can be calculated using simple math. The distance from \\(j\\) to \\(i\\) is calculated using simple euclidean distance. Of course one could take the earths curvature into account, but let’s keep it simple for now. Finally, the distance and value of cell \\(i\\) will be stored. Note, that the cells \\(i\\) and \\(j\\) can be identical. In this case \\(d\\) would be \\(0\\) and result in a math error due to division by zero. Therefore, we simply store a fraction of the raster resolution in this case. One could also store a very small number or even the true value of \\(i\\). However, while testing different values, this led to very pointy interpolation maps.\n// Distance (d) and value (z) vector\rstd::vector\u0026lt;double\u0026gt; d;\rstd::vector\u0026lt;double\u0026gt; z;\r// Iterate over all cells that are within the radius\rfor(int row_i = row_j-r_pxl; row_i \u0026lt;= row_j+r_pxl; row_i++){\rif(row_i \u0026gt; 0 \u0026amp;\u0026amp; row_i \u0026lt; rast_info.nrow){\rfor(int col_i = col_j-r_pxl; col_i \u0026lt;= col_j+r_pxl; col_i++){\rif(col_i \u0026gt; 0 \u0026amp;\u0026amp; col_i \u0026lt; rast_info.ncol){\r// Cell from row/col\rconst int i = row_i * rast_info.ncol + col_i;\rconst double i_value = x[i];\rif(!NumericVector::is_na(i_value)) {\r// XY from cell\rconst double y_i = rast_info.ymax - (row_i + 0.5) * rast_info.res;\rconst double x_i = rast_info.xmin + (col_i + 0.5) * rast_info.res;\r// Distance\rconst double dist = sqrt((x_j-x_i)*(x_j-x_i) + (y_j-y_i)*(y_j-y_i));\r// Save distance and value\rif(i == j){\rd.push_back(rast_info.res/4);\rz.push_back(i_value);\r} else if(dist \u0026lt;= radius) {\rd.push_back(dist);\rz.push_back(i_value);\r}\r}\r}\r}\r}\r}\r\r3. Sort by distance and select top n\rTo efficiently select only the top \\(n\\) values I have created a little helper function findBestIndices. It takes a distance vector d and the number of values N that should be returned, and returns N indices of d sorted by distance. So for example if we have a vector d = c(4,1,6,0) and N = 3, the function returns c(3, 1, 0) (C++ starts indexing from 0).\nstd::vector\u0026lt;int\u0026gt; findBestIndices(std::vector\u0026lt;double\u0026gt; \u0026amp;d, const int \u0026amp;N)\r{ std::vector\u0026lt;int\u0026gt; indices(d.size());\rstd::iota(indices.begin(), indices.end(), 0); // fill with 0,1,2,...\rstd::partial_sort(indices.begin(), indices.begin()+N, indices.end(),\r[\u0026amp;d](int i,int j) {return d[i]\u0026lt;d[j];});\rreturn std::vector\u0026lt;int\u0026gt;(indices.begin(), indices.begin()+N);\r}\rNow we can apply this function in our main loop:\n// 3. Sort by distance and select top n\rint nn = (d.size() \u0026lt; n) ? d.size() : n;\r// Index of n shortest distances\rstd::vector\u0026lt;int\u0026gt; idx = findBestIndices(d, nn);\r// And select value (z) and distance (d) in that order\rstd::vector\u0026lt;double\u0026gt; z_top_n;\rstd::vector\u0026lt;double\u0026gt; d_top_n;\rfor(auto t=idx.begin(); t!=idx.end(); ++t){\rz_top_n.push_back(z[*t]);\rd_top_n.push_back(d[*t]);\r}\r\r4. Compute IDW\rFinally, we have everything to interpolate the value for cell \\(j\\). Again, I’ve created a small helper function calc_idw that applies the equation from the beginning of this post.\ndouble calc_idw(std::vector\u0026lt;double\u0026gt; \u0026amp;d, std::vector\u0026lt;double\u0026gt; \u0026amp;v, const double b){\rdouble numerator = 0.0;\rdouble denominator = 0.0;\r// Sum from i to n\rfor(std::size_t i = 0; i \u0026lt; d.size(); i++){\rnumerator += v[i] / pow(d[i], b);\rdenominator += 1 / pow(d[i], b);\r}\rreturn numerator/denominator;\r}\rAnd include it into the main loop:\n// Compute IDW\rout[j] = calc_idw(d_top_n, z_top_n, b);\r\r\rComparison with gstat\rThe gstat R package provides a large set of functions useful for geostatistical modelling, prediction and simulation. I followed the instruction provided by the FU Berlin (Hartmann, Krois, and Waske 2018) and compared the results and computation time to the Rcpp method. Conveniently they have also conducted a cross validation to select the parameters \\(n = 43\\) and \\(\\beta = 1.5\\) to reduce RMSE.\nI have packed all steps for the two approaches into the helper functions dwd_rcpp and dwd_gstat, you can view them here.\nLet’s look at the visual comparison first.\nOn the first glance, both maps look very similar. Apparently the raster generartion using rasterize results in a small spatial offset compared to the gstat raster. However, the differences are marginal.\nNow that we know the algorithm works fine, let’s compare computation time.\nload(url(\u0026quot;https://userpage.fu-berlin.de/soga/300/30100_data_sets/East_Germany.RData\u0026quot;))\rlibrary(microbenchmark)\rmicrobenchmark(\rrcpp = dwd_rcpp(aoi = east.germany.states.sp, data = dwd.east.sp, n = 43, b = 1.5, resolution = 10000),\rgstat = dwd_gstat(aoi = east.germany.states.sp, data = dwd.east.sp, n = 43, b = 1.5, resolution = 10000)\r)\r## Unit: milliseconds\r## expr min lq mean median uq max neval cld\r## rcpp 215.3333 225.7391 233.3985 229.0763 233.6078 410.7200 100 a ## gstat 223.4818 232.3571 251.1311 237.3653 243.8096 421.1824 100 b\rAgain, both methods show very similar results. However, when we reduce the resolution (more cells) we clearly see the advantage of using Rcpp.\nmicrobenchmark(\rrcpp = dwd_rcpp(aoi = east.germany.states.sp, data = dwd.east.sp,\rn = 43, b = 1.5, resolution = 1000),\rgstat = dwd_gstat(aoi = east.germany.states.sp, data = dwd.east.sp, n = 43, b = 1.5, resolution = 1000)\r)\r## Unit: seconds\r## expr min lq mean median uq max neval cld\r## rcpp 1.888486 1.918858 1.968413 1.962389 1.971613 2.202879 100 a ## gstat 2.358264 2.423042 2.533372 2.516033 2.656117 2.845171 100 b\rAs mentioned previously, supporting multithreading with Rcpp is simple, too. The dwd_rcpp function supports multithreading, which enables us to compute rainfall interpolation for whole Germany quickly!\naoi \u0026lt;- raster::getData(country = \u0026quot;Germany\u0026quot;, level = 1) %\u0026gt;%\rst_as_sf() %\u0026gt;% st_transform(3035) %\u0026gt;%\rst_union() %\u0026gt;% st_as_sf()\rdwd.sf \u0026lt;- st_as_sf(dwd, coords = c(\u0026quot;LON\u0026quot;,\u0026quot;LAT\u0026quot;), crs = 4326) %\u0026gt;% st_transform(3035) %\u0026gt;% st_intersection(aoi) %\u0026gt;% rename(Rainfall = rain)\rRcpp:\ntime_start \u0026lt;- Sys.time()\rgermany_rcpp \u0026lt;- dwd_rcpp(aoi = aoi, data = dwd.sf,\rresolution = 500, ncores = 24)\rround(difftime(Sys.time(), time_start),1)\r## Time difference of 3.4 secs\rgstat:\ntime_start \u0026lt;- Sys.time()\rgermany_gstat \u0026lt;- dwd_gstat(aoi = aoi, data = dwd.sf,\rresolution = 500)\rround(difftime(Sys.time(), time_start),1)\r## Time difference of 43.1 secs\r\r\rConclusion\rIn this post I’ve demonstrated how the IDW algorithm can be implemented in C++ using Rcpp. The results match the output of the well established gstat R package. Single core computation time is lower using the Rcpp version, especially for more complex tasks (large number of observations; low raster resolution). But where the Rcpp function really stands out is the capability of multithreading. In my research of Greenspace Visibility I analyse millions of observer locations over a very large area of interest. Using the gstat function would take a long time, but utilizing all of my cores reduces computation time significantly. However, gstat also supports more complex interpolation methods (e.g. kriging).\nAs a next step I will try to include barriers as demonstrated by GISGeography (2016) to simulate the effect of noise barriers or visible obstacles.\nI have included the IDW interpolation algorithm in the GVI R package that also supports LINE and POLYGON features as the observer input:\nlibrary(GVI)\rgermany_rcpp \u0026lt;- sf_to_rast(observer = dwd.sf, v = \u0026quot;Rainfall\u0026quot;, aoi = aoi,\rbeta = 1.5, raster_res = 1000, cores = 22)\r\rReferences\rDunnington, Dewey. 2019. “Bathymetry \u0026amp; Lake Volume Estimation Using r.” https://fishandwhistle.net/post/2019/bathymetry-lake-volume-estimation-using-r/.\r\rGISGeography. 2016. “Inverse Distance Weighting (IDW) Interpolation.” https://gisgeography.com/inverse-distance-weighting-idw-interpolation/.\r\rHartmann, K., J. Krois, and B. Waske. 2018. “E-Learning Project SOGA: Statistics and Geospatial Data Analysis. Department of Earth Sciences, Freie Universitaet Berlin.” https://www.geo.fu-berlin.de/en/v/soga/Geodata-analysis/geostatistics/index.html.\r\rTobler, W. R. 1970. “A Computer Movie Simulating Urban Growth in the Detroit Region.” Economic Geography 46 (June): 234. https://doi.org/10.2307/143141.\r\rWilke, Sören. 2020. “A Practical Guide to Geospatial Interpolation with r.” https://swilke-geoscience.net/post/spatial_interpolation/.\r\r\r\r","date":1643846400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643899904,"objectID":"9fe812fed3712cedc787e8f68187907d","permalink":"/post/iwd/","publishdate":"2022-02-03T00:00:00Z","relpermalink":"/post/iwd/","section":"post","summary":"A fast implementation of the IDW algorithm using Rcpp. I compare the results to the well established gstat R package.","tags":["R","Rcpp","GIS"],"title":"Fast Inverse Distance Weighting (IDW) Interpolation with Rcpp","type":"post"},{"authors":["Sebastian Brinkmann","S.M. Labib"],"categories":null,"content":"The GVI R package helps researchers compute the Greenness Visibility Index (GVI) presented by Labib, Huck and Lindley (2021). The GVI is calculated using a Digital Surface Model (DSM), Digital Terrain Model (DTM) and Greenness Raster. GVI is written in C++ to provide fast and light weighted functionality.\nGo on GitHub for more information.\n","date":1625443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625476451,"objectID":"adf9bfdaf2eff2aa0a532bb59d0f8d30","permalink":"/publication/gvi-greenness-visibility-index-r-package/","publishdate":"2021-07-05T00:00:00Z","relpermalink":"/publication/gvi-greenness-visibility-index-r-package/","section":"publication","summary":"The GVI R package provides tools for computing a Greenness Visibility Index (GVI) surface from a DSM, DTM and Greenness Surface.","tags":["R","Greenspace","Health Geography"],"title":"GVI: Greenness Visibility Index R package","type":"publication"},{"authors":[],"categories":[],"content":"\r\rIn a previous posts I have introduced the Viewshed Greenness Visibility Index (VGVI) and demonstrated, how to fine tune the parameters for calculateing the viewsheds. In cooperation with Dr. S.M. Labib we have build the R package GVI, for easily calculating VGVI’s. The VGVI expresses the proportion of visible greenness to the total visible area and is calculated using a viewshed based on a Digital Surface Model (DSM). There are other methods to compute visible greenness, for example using Google Street View panorama images instead of a DSM (Li et al. 2015). Though the method we present has some advantages, as DSM and Landuse data is already being provided for public use for many regions worldwide. Furthermore, it is very easy to not only compute the overall visible greenness, but - for example - compute visible tree-coverage or visible blue-space. Such information is important to understand how specific build environment features affect health. I will demonstrate how to calculate visible tree-coverage in the end of this post.\nOn the GitHub website we have already provided examples on how to use the functions. However, a use case of this R package for researchers is to compute the VGVI for a large study area.\nTherefore, in this post, I’d like to provide a workflow for a large area of interest, using the City of Vancouver as my study area.\nInput\rFor computing the VGVI, we need three raster layers: the Digital Terrain Model (DEM) and Digital Surface Model (DSM) and a Greenspace Mask. The Greenspace Mask is a binary raster based on a Land Cover Classification map, where 1 = vegetation and 0 = no vegetation. I have also included bluespaces (e.g. lakes and rivers) to the greenspace mask with the value 1, since these features also seem to provide mental health benefits (White et al. 2021).\nThe data can be downloaded from Zenodo and read in R like this.\n### Load libraries\rlibrary(terra) # handling raster data\rlibrary(sf) # handling shapefiles\rlibrary(GVI) # computing the VGVI\rlibrary(dplyr) # data wrangeling\r# Folder where the data has been downloaded\rworkdir \u0026lt;- \u0026quot;H:/Vancouver/Vancouver_Sample_Data/\u0026quot;\r# Load DTM, DSM and Land Cover\rdtm \u0026lt;- rast(file.path(workdir, \u0026quot;Vancouver_DTM_1m.tif\u0026quot;))\rdsm \u0026lt;- rast(file.path(workdir, \u0026quot;Vancouver_DSM_1m.tif\u0026quot;))\rlulc \u0026lt;- rast(file.path(workdir, \u0026quot;Vancouver_LULC_2m.tif\u0026quot;))\r# Reclassify values for the binary greenspace mask\rrcl_mat \u0026lt;- matrix(c(1, 6, 0, # no vegetation\r6, 13, 1, # vegetation and water\r13, 14, 0), # no vegetation\rncol = 3, byrow = TRUE)\rgreenspace \u0026lt;- classify(lulc, rcl = rcl_mat, include.lowest = TRUE)\rwriteRaster(greenspace, file.path(workdir, \u0026quot;Vancouver_GS_2m.tif\u0026quot;))\rBelow I have provided a interactive map of a smaller region, to compare the DTM, DSM and Landuse. In my other post I have also listed all classes of the Landuse map in detail.\n\r\nWe also need the observer locations where the VGVI should be computed. In our example we could simply use all coordinates of the whole DSM. However, we can’t compute the VGVI from inside buildings, and it wouldn’t make sense to compute VGVI on water (unless you are interested in the view of stand-up paddlers). Therefore, in the next step, we only use the coordinates of useful cells from the Land Cover Classification map and convert it to a sf-point feature.\n# Useful Landcover Classification codes\ruseful_codes \u0026lt;- c(2:11, 13)\r# Get XY-coordinates\rxy_coords \u0026lt;- xyFromCell(lulc, which(values(lulc) %in% useful_codes)) %\u0026gt;% as_tibble()\r# Convert to shapefile\rvancouver_2m_sf \u0026lt;- st_as_sf(xy_coords, coords = c(\u0026quot;x\u0026quot;, \u0026quot;y\u0026quot;), crs = 26910)\r# Save sf\rwrite_sf(vancouver_2m_sf, file.path(workdir, \u0026quot;Vancouver_2m_xy.gpkg\u0026quot;))\rCreating and writing the shapefile might take some time, as it contains 16.741.566 features. At this point I would recommend to restart the R session and clean the environment to free the RAM.\n\rVGVI\rBefore computing the VGVI using the vgvi_from_sf function from our GVI R package, I would recommend to think about some important parameters. I have partially covered this in my last post, where I talked about the parameters raster_res and max_distance. So far, we have not provided recommendations for fitting the weights parameters m, b, and mode, because we need to conduct more research in this area. However, in our study area, m = 1 and b = 3, using the exponential function (see plot below) for calculating the distance decay weights seems sufficient.\nComputing VGVI for a large area using multiple CPU cores can be RAM expensive. In addition to that, loading the complete Vancouver_2m_xy.gpkg shapefile into the R session is very RAM expensive, too. Therefore, I’ll make use of a SQL statement, to load the shapefile step by step. This way, the computation is more efficient and faster. Furthermore, by saving after every step, it is very easy to continue the script at the latest position in case of an unexpected system failure.\nlibrary(magrittr)\rlibrary(sf)\rlibrary(terra)\rlibrary(GVI)\roptions(show.error.messages = T)\r# Set your cores here!\rcores \u0026lt;- 22\r# Set workdir\rworkdir \u0026lt;- \u0026quot;H:/Vancouver/Vancouver_Sample_Data/\u0026quot;\r# Make dir for saving the VGVI output continuously\rdir.create(file.path(workdir, \u0026quot;out\u0026quot;))\r# Load raster data\rdtm \u0026lt;- rast(file.path(workdir, \u0026quot;Vancouver_DTM_1m.tif\u0026quot;))\rdsm \u0026lt;- rast(file.path(workdir, \u0026quot;Vancouver_DSM_1m.tif\u0026quot;))\rgreenspace \u0026lt;- rast(file.path(workdir, \u0026quot;Vancouver_GS_2m.tif\u0026quot;))\r# Sequence for the SQL statement\rsql_seq \u0026lt;- as.integer(seq(1, 16741566, length.out = 201))\rfor(i in 2:max(seq_along(sql_seq))) {\rcat(paste0(\u0026quot;Iteration \u0026quot;, i-1, \u0026quot;/\u0026quot;, length(sql_seq)-1, \u0026quot;:\\n\u0026quot;))\r# Load shapefile with SQL statement\rvancouver_sf \u0026lt;- st_read(\rfile.path(workdir, \u0026quot;Vancouver_2m_xy.gpkg\u0026quot;),\rquery = paste(\u0026quot;SELECT * FROM \\\u0026quot;Vancouver_2m_xy\\\u0026quot; WHERE fid BETWEEN\u0026quot;, sql_seq[i-1], \u0026quot;AND\u0026quot;, sql_seq[i]),\rquiet = TRUE)\r# Compute VGVI\rvancouver_vgvi \u0026lt;- vgvi_from_sf(observer = vancouver_sf,\rdsm_rast = dsm, dtm_rast = dtm, greenspace_rast = greenspace,\rmax_distance = 550, observer_height = 1.7,\rraster_res = 2,\rm = 1, b = 3, mode = \u0026quot;exponential\u0026quot;,\rcores = cores, chunk_size = 10000, folder_path = file.path(workdir, \u0026quot;out\u0026quot;),\rprogress = TRUE)\rcat(\u0026quot;\\n\u0026quot;)\r}\rI recommend to save the code from above in a separate R script (e.g. vgvi_Vancouver_2m.R) and call this script from the console. On Linux you can do this with the command:\nsudo R CMD BATCH vgvi_Vancouver_2m.R \u0026amp;\nThis will run the R script in background and saves the output in a new file vgvi_Vancouver_2m.Rout. You can check the progress by calling cat vgvi_Vancouver_2m.Rout. In addition, I would recommend checking your CPU and RAM usage. I really like the htop tool for this!\n\rVGVI to Raster\rIn most cases we prefer working with raster layers instead of millions of point features. Therefore, we will combine all the VGVI shapefiles from the previous step and convert them to a single raster (we will include this functionality in our package in the future). Also, I found it useful to smooth the final product by applying a moving window (focal) smoothing function.\nlibrary(magrittr)\rlibrary(sf)\rlibrary(terra)\rlibrary(raster)\rworkdir \u0026lt;- \u0026quot;H:/Vancouver/Vancouver_Sample_Data/\u0026quot;\r# List all shapefiles in the out-folder\rvgvi_paths \u0026lt;- list.files(file.path(workdir, \u0026quot;out\u0026quot;), full.names = TRUE, pattern = \u0026quot;.gpkg\u0026quot;)\r# Load the Greenspace Mask\rgreenspace \u0026lt;- rast(file.path(workdir, \u0026quot;Vancouver_GS_2m.tif\u0026quot;))\rpb = txtProgressBar(min = 0, max = length(vgvi_paths), initial = 0, style = 3)\rfor (i in seq_along(vgvi_paths)) {\r# Convert shapefile to raster, the Greenspace raster will be # used as a template for CRS and extent\rthis_rast \u0026lt;- terra::rasterize(terra::vect(vgvi_paths[i]), greenspace, \u0026quot;VGVI\u0026quot;)\rnames(this_rast) \u0026lt;- \u0026quot;VGVI\u0026quot;\rif (i == 1) {\rterra::writeRaster(x = this_rast, filename = file.path(workdir, \u0026quot;big_rast.tif\u0026quot;),\roverwrite = TRUE)\r} else {\rterra::writeRaster(terra::merge(x = this_rast, y = rast(file.path(workdir, \u0026quot;big_rast.tif\u0026quot;))),\rfilename = file.path(workdir, \u0026quot;big_rast.tif\u0026quot;),\roverwrite = TRUE)\r}\rsetTxtProgressBar(pb,i)\r}\r# Clean data\rbig_rast \u0026lt;- terra::rast(file.path(workdir, \u0026quot;big_rast.tif\u0026quot;)) %\u0026gt;%\rterra::classify(rcl = matrix(c(-Inf, 0, 0),\rncol = 3,\rbyrow = TRUE))\r# Apply smoothing and write raster\rbig_rast %\u0026gt;%\rterra::focal(3, fun = median, na.rm = TRUE) %\u0026gt;%\rterra::mask(big_rast) %\u0026gt;%\rterra::writeRaster(file.path(workdir, \u0026quot;big_rast_smooth.tif\u0026quot;))\r\rTree-Coverage Visibility\rAs already mentioned in the beginning, it may be of interest to model visible tree-cover or visible blue-spaces or similar visibility assessments. Since we used a Landcover Classification map for differentiating between green vs. no-green, it is now very simple and straight forward to analyze visible tree-cover. As we did before, we need to classify coniferous and deciduous trees as 1, and the rest as 0.\nrcl_mat \u0026lt;- matrix(c(1, 6, 0, # no trees\r6, 8, 1, # coniferous and deciduous trees\r8, 14, 0), # no trees\rncol = 3, byrow = TRUE)\rtree_cover \u0026lt;- classify(lulc, rcl = rcl_mat, include.lowest = TRUE)\rBased on this new binary tree-cover mask, the Viewshed Tree-Cover Visibility Index (VTVI) can be calculated using the scripts from above. I have excluded observer locations that are underneath trees. Below you can see the result of the VGVI and VTVI. As you can see, they have not been computed for areas with buildings or water. In the VGVI layer you can also see, that cells which are located underneath trees have an extremely high VGVI value. This is because the viewshed algorithm can’t “see” beyond those trees and returns only one single visible cell, which is green. We are currently working on ways for solving this limitation.\n\r\nWhen looking at the VTVI layer, higher values are rarely achieved because it is generally harder to view trees compared to overall vegetation. The Langara Golf Course in the south and the Little Mountain park in the north are the two areas with the highest VTVI values. The residential area in the east also achieved relatively high values. This might be explained by the very large London plane trees (Platanus × acerifolia), European beech trees (Fagus sylvatica) and horse chestnut trees (Aesculus hippocastanum) that have been planted in the side alleys.\n\r","date":1625184000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625231787,"objectID":"4fba8e3413f34f51ac327b0b2e886ed2","permalink":"/post/visible-greenness-exposure-index-an-example-workflow-for-the-city-of-vancouver/","publishdate":"2021-07-02T00:00:00Z","relpermalink":"/post/visible-greenness-exposure-index-an-example-workflow-for-the-city-of-vancouver/","section":"post","summary":"Example workflow for a large study area when using the GVI R package","tags":["R","Greenspace","Health Geography"],"title":"Visible Greenness Exposure Index - An example workflow for the City of Vancouver","type":"post"},{"authors":[],"categories":[],"content":"\r\rAs part of my Bachelor Thesis I am analyzing the effects of visible green- and bluespaces on mental health based on a medical study in Vancouver. The area of interest covers Vancouver City, Burnaby and Surrey.\nTo analyze the effect of visible greenness I’ll be using the Viewshed Greenness Visibility Index (VGVI). The VGVI expresses the proportion of visible greenness to the total visible area based on a viewshed. The estimated VGVI values range between 0 and 1, where 0 = no green cells are visible, and 1 = all of the visible cells are green. In a recent post I have demonstrated how to calculate the VGVI, and in my R package GVI (currently only available on GitHub) I have provided fast functions to compute the VGVI.\nTo calculate the VGVI for an observer, the viewshed of this point needs to be computed first - hence the name Viewshed Greenness Visibility Index. The viewshed function of the GVI package does exactly that. The basic idea is to apply a buffer on the observer position. Now we can “simply” check every point in this area, whether it is visible or not.\nTo do so, we need a Digital Surface Model (DSM), Digital Terrain Model (DTM) and the observer location as input data for the viewshed function.\n# Load libraries\rlibrary(dplyr)\rlibrary(sf)\rlibrary(GVI)\rlibrary(terra)\rworkdir \u0026lt;- \u0026quot;H:/Vancouver/Vancouver_RS_Data/\u0026quot;\r# Load DSM and DEM\rdsm \u0026lt;- rast(file.path(workdir, \u0026quot;DSM.tif\u0026quot;))\rdtm \u0026lt;- rast(file.path(workdir, \u0026quot;DTM.tif\u0026quot;))\r# Sample observer location\rst_observer \u0026lt;- sfheaders::sf_point(c(487616.2, 5455970)) %\u0026gt;% st_sf(crs = st_crs(26910))\r# Compute Viewshed\rviewshed_1 \u0026lt;- GVI::viewshed(observer = st_observer,\rdsm_rast = dsm, dtm_rast = dtm,\rmax_distance = 250, resolution = 1,\robserver_height = 1.7, plot = TRUE)\rIn the plot above, the Digital Surface Model (DSM) is visualized on the left. The viewshed is shown on the right, where green = visible and yellow = no-visible area. The observer in the example - visualized as the red dot - can see far over the sports field to the west and has little visibility to the east.\nNext, we would compute the VGVI based on the viewshed and a greenspace mask. However, in this post I would like to focus on the two parameters distance and resolution. Distance describes the radius of the buffer around the observer location. The resolution parameter describes the resolution that the rasters should be aggregated to. High resolution yields the most realistic results, but on cost of computation time.\nSensitivity Analysis\rWhen computing the VGVI for a single, or few points, you wouldn’t need to consider using a lower resolution or adjusting the maximum distance. The computation time is rather low even at high resolution with a high maximum distance (e.g. 800m with 1m resolution: 5.5 secs). However, when computing the VGVI for a larger area - like the whole City of Vancouver - it is very important to consider these parameters. In the following I conduct a sensitivity analysis for the two parameters.\nSamples\rFor the sensitivity analysis of the two parameters I’ll use a representative sample of 4000 observer locations.\nset.seed(1234)\r# Grab 4000 random points. The Van_2m_xy.gpkg file has 108.320.000 points\rfid_sample \u0026lt;- sample(1:108320000, 4000)\r# Read the shapefile using an SQL statement\rmy_query = paste(\u0026quot;SELECT * FROM \\\u0026quot;Van_2m_xy\\\u0026quot; WHERE fid IN (\u0026quot;, toString(fid_sample), \u0026quot;)\u0026quot;)\rsf_sample \u0026lt;- st_read(file.path(workdir, \u0026quot;Van_2m_xy.gpkg\u0026quot;),\rquery = my_query,\rquiet = TRUE)\r\rDistance\rIn the example above I have used a distance of only 250 meters. Below I have computed the VGVI for the same observer location, but with a 800 meter radius.\n# Compute Viewshed\rviewshed_2 \u0026lt;- GVI::viewshed(observer = st_observer,\rdsm_rast = dsm, dtm_rast = dtm,\rmax_distance = 800, resolution = 1,\robserver_height = 1.7, plot = TRUE)\rIncreasing the distance to 800 meters doesn’t really affect the visible area. Most of what can be seen at this specific observer location, is withing the smaller 250 m radius. But the computation time decreases from 5.5 to 0.3 seconds!\nTherefore, it’s important to investigate if the relationship between distance and visible area. The function below calculates the proportion of visible area for each distance value of the viewshed raster.\nvisibleDistance \u0026lt;- function(x) {\r# Get XY coordinates of cells\rxy \u0026lt;- terra::xyFromCell(x, which(!is.na(x[])))\r# Calculate euclidean distance from observer to cells\rcentroid \u0026lt;- colMeans(terra::xyFromCell(x, which(!is.na(x[]))))\rdxy = round(sqrt((centroid[1] - xy[,1])^2 + (centroid[2] - xy[,2])^2))\rdxy[dxy==0] = min(dxy[dxy!=0])\r# Combine distance and value\rcbind(dxy, unlist(terra::extract(x, xy), use.names = FALSE)) %\u0026gt;%\ras_tibble() %\u0026gt;% rename(visible = V2) %\u0026gt;% arrange(dxy) %\u0026gt;% group_by(dxy) %\u0026gt;% # Mean visible area for each distinct distance value\rsummarise(visible = mean(visible)) %\u0026gt;% ungroup() %\u0026gt;% return()\r}\rLet’s apply it on the second viewshed:\n\r\rDistance\rVisibility\r\r\r\r1\r100.0%\r\r2\r100.0%\r\r3\r100.0%\r\r4\r100.0%\r\r5\r100.0%\r\r796\r0.2%\r\r797\r0.1%\r\r798\r0.1%\r\r799\r0.1%\r\r800\r0.2%\r\r\r\rTo find the specific distance threshold of my area of interest, I’ll use the sample of 4000 points and compute the viewshed and proportion of visible area for each distance value.\nfor(i in 1:nrow(sf_sample)) {\r# Viewshed\rthis_dist \u0026lt;- viewshed(observer = sf_sample[i, ], max_distance = 1000,\rdsm_rast = dsm, dtm_rast = dtm) %\u0026gt;%\r# Costum function visibleDistance()\r# Add to \u0026quot;out\u0026quot;\rif (i == 1) {\rout \u0026lt;- this_dist\r} else {\rout \u0026lt;- rbind(out, this_dist)\r}\r}\rThe plot below indicates, that visibility decreases with increasing distance. Interestingly, there are two distance levels where visibility increases locally, at 250 m and 500 m. This might be due to city planning effects. Most points are located at streets, maybe parks are planned to be evenly distributed in the Vancouver Metropolitan area for close, equal access.\nBased on this analysis I set the distance parameter to 550 meters.\n\rResolution\rThe resolution parameter describes the resolution that the rasters should be aggregated to. Using the distance value of 550 meters, the viewshed with a 1 m resolution has 1.210.000 cells and takes 1 second. A viewshed with 5 meter resolution has 48.400 cells and takes only 0.5 seconds to compute. However, higher resolution yields in more accurate results. Below I have provided an example for comparison.\nThe function below calculates the similarity of visibility for each resolution compared to the 1 meter resolution.\ncompare_resolution \u0026lt;- function(observer, dsm_path, dtm_path) {\rviewshed_tbl \u0026lt;- lapply(c(1, 2, 5, 10), FUN = function(x) {\r# Get values of viewshed with resolution x\rtime_a \u0026lt;- Sys.time()\rall_value \u0026lt;- viewshed(observer = observer, dsm_rast = rast(dsm_path), dtm_rast = rast(dtm_path),\rmax_distance = 550, observer_height = 1.7, resolution = x) %\u0026gt;%\rvalues() %\u0026gt;%\rna.omit()\rtime_b \u0026lt;- Sys.time()\r# Return Distance, proportion of visible area and computation time\rreturn(tibble(\rResolution = x,\rSimilarity = length(which(all_value == 1)) / length(all_value),\rTime = as.numeric(difftime(time_b, time_a, units = \u0026quot;secs\u0026quot;))\r))\r}) %\u0026gt;% do.call(rbind, .)\rviewshed_tbl %\u0026gt;% rowwise() %\u0026gt;% mutate(Similarity = min(viewshed_tbl[1,2], Similarity) / max(viewshed_tbl[1,2], Similarity)) %\u0026gt;% return()\r}\rThe boxplots below confirm the assumption, that similarity decreases with increasing resolution. Mean computation time for 1 m, 2 m, 5 m and 10 m resolution was 4.80 seconds, 1.05 seconds, 0.85 seconds and 0.75 seconds, respectively. A resolution of 2 meters seems to be a optimal compromise, as it has a ~75% similarity, but the computation time decreases to about \\(\\frac{1}{5}\\), too.\n\r\rConclusion\rIn this post I have conducted a sensitivity analysis on the parameters distance and resolution for the viewshed function in the Vancouver Metropolitan Area. The thresholds for the distance and resolution is 550 meters and 2 meters, respectively.\nThe complete study area contains 108.320.000 points, computation time on a high performance server is ~20 days. Therefore, it is important to critically think about these parameters beforehand.\n\r","date":1624320000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624377963,"objectID":"9a0d44bba0cd6f6c2bb30f959b7d25dc","permalink":"/post/visibility-sensitivity-analysis/","publishdate":"2021-06-22T00:00:00Z","relpermalink":"/post/visibility-sensitivity-analysis/","section":"post","summary":"Thinking critically about parameters before running the code is always important. In this post I will explain how to set important parameters when conducting a Visibility Analysis.","tags":["Greenspace","Exploratory Spatial Data Analysis (ESDA)","R"],"title":"Visibility - Sensitivity Analysis","type":"post"},{"authors":[],"categories":[],"content":"\r\r\r\rbody {\rtext-align: justify}\r\rIn our recent publication from 2020 we analyzed COVID-19 incidence and socioeconomic, infrastructural, and built environment characteristics using a multimethod approach. There are 401 counties in Germany; as shown in the figure below, these vary in size, such that the counties in Southern Germany are generally smaller with higher population densities. Natural log-transformed age-adjusted incidence rates of COVID-19 as of April 1st are shown, indicating spatial variation between the northeast and south-southwest of the study area. After conducting a throughout spatial exploratory analysis, we used a Bayesian Additive Regression Trees (BART; Chipman, George, and McCulloch (2010)) model, to identify important socioeconomic and built environment covariates with COVID-19 incidence rate. BART is a ensemble-of-trees method, such as random forests (Breiman 2001) and stochastic gradient boosting (Friedman 2002).\nTree-based regression models have an advantage, as they can flexibly fit interactions and non-linearities. A sum-of-trees model - such as BART or random forest - has an even greater ability than a single-tree model. However, BART differs from these two examples, as it uses a underlying Bayesian probability model rather than a pure algorithm (Kapelner and Bleich 2016). One of the advantages of using a Bayesian approach is, that it computes Bayesian posterior distributions to approximate the nonparametric model parameters. The priors aim to prevent a single regression from dominating, thus reducing the risk of overfitting (Kapelner and Bleich 2016; Scarpone et al. 2020).\nFor our analysis we have used the R package bartMachine (Kapelner and Bleich 2016). Unfortunately bartMachine does not support tibble objects as input features, but apart from that it’s intuitive and simple to use.\nIn this post I will use the data we have used in our COVID-19 paper, to analyze age-adjusted incidence rates of COVID-19 for German counties. Even though the BART model has great predictive power, we will not use it to predict new cases of COVID-19, but rather use it as a exploratory tool to understand, what factors contribute to the spreading of COVID-19 and how they interact with the incidence rate.\nI want to make it clear, that I will use data of one specific date. We have chosen the 1st April 2020, to analyze only the first wave of COVID-19 in Germany. A friend of mine currently analyses what effects contributed to the second and third waves. Even though there are many factors, that kept being important, many features gained or lost importance and some even showed a inverted effect.\nTherefore, BART is used as an exploratory tool and with the help of Partial Dependence Plots we will gain insight of the marginal effects of the important predictors of COVID-19.\nI will not focus on pre-modelling exploratory data analysis, nor explain the data engineering here. But feel free to read the paper or contact me.\nData download and pre-processing\rFirst, we need to load the packages and set the memory size and number of cores that bartMachine should be using.\n# Set to use 45 GB memory - adjust this to your resources\roptions(java.parameters = \u0026quot;-Xmx45g\u0026quot;)\r# Load packages\rlibrary(bartMachine)\rlibrary(dplyr)\r# Set to run on 20 threads - adjust this to your resources\rset_bart_machine_num_cores(20)\r## bartMachine now using 20 cores.\rI would suggest, that you double check if the correct amount of RAM has been made available, when loading bartMachine. If the message states a completely different amount of memory, try to manually write the java.parameters string, instead of copy\u0026amp;pasting.\nNext, we need to download the data and normalize the church density (Rch_den) variable.\n# Function for linear stretching. New range: 0-1\rrange0_1 \u0026lt;- function(x){(x-min(x))/(max(x)-min(x))}\r# Download data\rdata \u0026lt;- read.csv(\u0026quot;https://github.com/CHEST-Lab/BART_Covid-19/raw/master/Data/GermanyTraining.csv\u0026quot;,\rstringsAsFactors = F) %\u0026gt;%\rmutate(Rch_den = range0_1(Rch_den),\rNUTS2_Fact = as.factor(NUTS2_Fact), BL_ID = as.factor(BL),\rS_109 = as.factor(S_109))\r# Select variables: Lat/ Long, BL, NUTS2, socioeconomic, build environment and age adjusted case rate\rdata \u0026lt;- data[c(374, 3, 4, 5, 38, 28, 65:372)]\r\r\rAdjRate\r\rX\r\rY\r\rNUTS2_Fact\r\rBL_ID\r\rEWZ\r\rS_001\r\rS_002\r\rS_003\r\rS_004\r\rS_005\r\rS_006\r\rS_007\r\rS_008\r\rS_009\r\rS_010\r\rS_011\r\rS_012\r\rS_013\r\rS_014\r\rS_015\r\rS_016\r\rS_017\r\rS_018\r\rS_019\r\rS_020\r\rS_021\r\rS_022\r\rS_023\r\rS_024\r\rS_025\r\rS_026\r\rS_027\r\rS_028\r\rS_029\r\rS_030\r\rS_031\r\rS_032\r\rS_033\r\rS_034\r\rS_035\r\rS_036\r\rS_037\r\rS_038\r\rS_039\r\rS_040\r\rS_041\r\rS_042\r\rS_043\r\rS_044\r\rS_045\r\rS_046\r\rS_047\r\rS_048\r\rS_049\r\rS_050\r\rS_051\r\rS_052\r\rS_053\r\rS_054\r\rS_055\r\rS_056\r\rS_057\r\rS_058\r\rS_059\r\rS_060\r\rS_061\r\rS_062\r\rS_063\r\rS_064\r\rS_065\r\rS_066\r\rS_067\r\rS_068\r\rS_069\r\rS_070\r\rS_071\r\rS_072\r\rS_073\r\rS_074\r\rS_075\r\rS_076\r\rS_077\r\rS_078\r\rS_079\r\rS_080\r\rS_081\r\rS_082\r\rS_083\r\rS_084\r\rS_085\r\rS_086\r\rS_087\r\rS_088\r\rS_089\r\rS_090\r\rS_091\r\rS_092\r\rS_093\r\rS_094\r\rS_095\r\rS_096\r\rS_097\r\rS_098\r\rS_099\r\rS_100\r\rS_101\r\rS_102\r\rS_103\r\rS_104\r\rS_105\r\rS_106\r\rS_107\r\rS_108\r\rS_109\r\rS_110\r\rS_111\r\rS_112\r\rS_113\r\rS_114\r\rS_115\r\rS_116\r\rS_117\r\rS_118\r\rS_119\r\rS_120\r\rS_121\r\rS_122\r\rS_123\r\rS_124\r\rS_125\r\rS_126\r\rS_127\r\rS_128\r\rS_129\r\rS_130\r\rS_131\r\rS_132\r\rS_133\r\rS_134\r\rS_135\r\rS_136\r\rS_137\r\rS_138\r\rS_139\r\rS_140\r\rS_141\r\rS_142\r\rS_143\r\rS_144\r\rS_145\r\rS_146\r\rS_147\r\rS_148\r\rS_149\r\rS_150\r\rS_151\r\rS_152\r\rS_153\r\rS_154\r\rS_155\r\rS_156\r\rS_157\r\rS_158\r\rS_159\r\rS_160\r\rS_161\r\rS_162\r\rS_163\r\rS_164\r\rS_165\r\rS_166\r\rS_167\r\rS_168\r\rS_169\r\rS_170\r\rS_171\r\rS_172\r\rS_173\r\rS_174\r\rS_175\r\rS_176\r\rM_km2\r\rT_km2\r\rP_km2\r\rS_km2\r\rT_km2_1\r\rAll_R_2\r\rM_pop\r\rT_pop\r\rP_pop\r\rS_pop\r\rT_pop_1\r\rAll_R_p\r\rtot_R\r\rlib_km2\r\runi_km2\r\rsch_km2\r\rcll_km2\r\rkid_km2\r\rply_km2\r\rthe_km2\r\rngh_km2\r\rcin_km2\r\rpub_km2\r\rbar_km2\r\rstd_km2\r\rsc_km2\r\rhsp_km2\r\rdoc_km2\r\rmll_km2\r\rdc_km2\r\rcon_km2\r\rsup_km2\r\rpst_km2\r\rth_km2\r\rcc_km2\r\rnh_km2\r\rac_km2\r\rphr_km2\r\rrst_km2\r\rff_km2\r\rcaf_km2\r\rfc_km2\r\rbir_km2\r\rbak_km2\r\rchm_km2\r\rdot_km2\r\rhar_km2\r\rprk_km2\r\rRch_km2\r\rRmu_km2\r\rRth_km2\r\rAll_P_2\r\rlib_pop\r\runi_pop\r\rsch_pop\r\rcoll_pp\r\rkid_pop\r\rplay_pp\r\rthea_pp\r\rnigh_pp\r\rcin_pop\r\rpub_pop\r\rbar_pop\r\rstad_pp\r\rsc_pop\r\rhosp_pp\r\rdoc_pop\r\rmall_pp\r\rdc_pop\r\rcon_pop\r\rsup_pop\r\rpost_pp\r\rth_pop\r\rcc_pop\r\rnh_pop\r\rac_pop\r\rphar_pp\r\rrest_pp\r\rff_pop\r\rcafe_pp\r\rfc_pop\r\rbier_pp\r\rbake_pp\r\rchem_pp\r\rdoit_pp\r\rhair_pp\r\rpark_pp\r\rRch_pop\r\rRmu_pop\r\rRoth_pp\r\rAll_P_p\r\rtot_P\r\rlib_den\r\runi_den\r\rsch_den\r\rcoll_dn\r\rkid_den\r\rplay_dn\r\rthea_dn\r\rnigh_dn\r\rcin_den\r\rpub_den\r\rbar_den\r\rstad_dn\r\rsc_den\r\rhosp_dn\r\rdoc_den\r\rmall_dn\r\rdc_den\r\rcon_den\r\rsup_den\r\rpost_dn\r\rth_den\r\rcc_den\r\rnh_den\r\rac_den\r\rphar_dn\r\rrest_dn\r\rff_den\r\rcafe_dn\r\rfc_den\r\rbier_dn\r\rbake_dn\r\rchem_dn\r\rdoit_dn\r\rhair_dn\r\rpark_dn\r\rRch_den\r\rRmu_den\r\rRoth_dn\r\rAll_P_d\r\rPop_Den\r\r\r\r\r\r27.37\r\r9.44\r\r54.78\r\r108\r\rSchleswig-Holstein\r\r89504\r\r8.9\r\r76.0\r\r19.3\r\r7.9\r\r12.5\r\r43.8\r\r14.5\r\r60.3\r\r8.1\r\r31.8\r\r94.8\r\r24.1\r\r-10.9\r\r72.1\r\r27.7\r\r44.1\r\r51.8\r\r18.8\r\r48.6\r\r22.8\r\r39.9\r\r17.2\r\r32.9\r\r85.0\r\r74.5\r\r2.9\r\r2.6\r\r5.5\r\r9.8\r\r11.9\r\r9.1\r\r23.8\r\r19.6\r\r9.6\r\r20.2\r\r10.6\r\r8.2\r\r2.4\r\r42.2\r\r6.1\r\r6.6\r\r3.0\r\r19.0\r\r30.2\r\r14.3\r\r10.0\r\r11.7\r\r0.75\r\r78.80\r\r2.3\r\r70.3\r\r48.2\r\r34.0\r\r92.1\r\r109.0\r\r44.7\r\r13.2\r\r91.2\r\r9.8\r\r29.5\r\r6.1\r\r8.5\r\r15.7\r\r14.0\r\r2.91\r\r1527\r\r2333\r\r1278.6\r\r2986\r\r16.0\r\r17.6\r\r24258\r\r11.3\r\r3375\r\r2992\r\r3373\r\r2965.5\r\r3.8\r\r52.6\r\r24.4\r\r6.4\r\r40.9\r\r1.0\r\r14.9\r\r4568.9\r\r444.4\r\r50.4\r\r15.6\r\r27.1\r\r-2.4\r\r9.47\r\r369.1\r\r29.6\r\r30.1\r\r100.3\r\r55.7\r\r123.9\r\r35.2\r\r15.8\r\r92.5\r\r45.2\r\r69.1\r\r7.0\r\r371.4\r\r1282.4\r\r1.3\r\r767.3\r\r0.0\r\r2\r\r0\r\r0\r\r1\r\r156\r\r2309\r\r13725\r\r16.2\r\r23.5\r\r19.6\r\r26.5\r\r7.2\r\r19.1\r\r7.41\r\r25.6\r\r134.5\r\r6.24\r\r1.80\r\r5.1\r\r5\r\r98\r\r0\r\r0\r\r0\r\r500\r\r92\r\r543\r\r90\r\r602\r\r89\r\r180\r\r100\r\r478\r\r52.4\r\r34.2\r\r27.7\r\r14.0\r\r7.7\r\r3.6\r\r3.2\r\r2.3\r\r1.5\r\r19.8\r\r3.5\r\r40.1\r\r1.6\r\r131.7\r\r30.9\r\r6.23\r\r42.5\r\r62.0\r\r18.1\r\r25.3\r\r5.8\r\r67.8\r\r8.5\r\r1.9\r\r35.2\r\r92.5\r\r100.0\r\r42826.6\r\r4.1\r\r51.8\r\r24.8\r\r97.0\r\r34.8\r\r48.8\r\r16.4\r\r0.00\r\r0.62\r\r0.44\r\r0.44\r\r0.95\r\r2.45\r\r0.00\r\r33.81\r\r24.40\r\r24.01\r\r52.45\r\r134.66\r\r120.52\r\r0.08\r\r0.00\r\r0.08\r\r0.06\r\r0.30\r\r1.67\r\r0.10\r\r0.12\r\r0.04\r\r0.91\r\r0.08\r\r0\r\r0.08\r\r0.00\r\r0.91\r\r0.00\r\r0.04\r\r0.30\r\r0.41\r\r0.20\r\r0.00\r\r0.12\r\r0.00\r\r0.06\r\r0.37\r\r1.71\r\r1.24\r\r0.85\r\r0\r\r0.00\r\r1.02\r\r0.22\r\r0.04\r\r1.26\r\r0.02\r\r0.04\r\r0.04\r\r0.06\r\r12.46\r\r4.47\r\r0.00\r\r4.47\r\r3.35\r\r16.76\r\r91.62\r\r5.59\r\r6.70\r\r2.23\r\r50.28\r\r4.47\r\r0\r\r4.47\r\r0.00\r\r50.28\r\r0.00\r\r2.23\r\r16.76\r\r22.35\r\r11.17\r\r0.00\r\r6.70\r\r0.00\r\r3.35\r\r20.11\r\r93.85\r\r68.15\r\r46.93\r\r0\r\r0.00\r\r55.86\r\r12.29\r\r2.23\r\r69.27\r\r1.12\r\r2.23\r\r2.23\r\r3.35\r\r684.89\r\r613\r\r0\r\r0\r\r0.00\r\r0\r\r0.01\r\r0.16\r\r0.01\r\r0.01\r\r0\r\r0.27\r\r0.00\r\r0\r\r0.00\r\r0\r\r0.26\r\r0\r\r0\r\r0.03\r\r0.03\r\r0.01\r\r0\r\r0\r\r0\r\r0\r\r0.02\r\r0.40\r\r0.29\r\r0.18\r\r0\r\r0\r\r0.23\r\r0.01\r\r0\r\r0.32\r\r0\r\r0.03\r\r0\r\r0\r\r0.33\r\r4566\r\r\r\r49.54\r\r10.13\r\r54.32\r\r108\r\rSchleswig-Holstein\r\r247548\r\r9.1\r\r72.0\r\r22.6\r\r6.6\r\r8.9\r\r33.1\r\r14.9\r\r63.2\r\r8.8\r\r37.8\r\r310.5\r\r3.2\r\r136.2\r\r67.3\r\r32.4\r\r38.9\r\r51.5\r\r19.2\r\r48.9\r\r21.3\r\r39.3\r\r17.5\r\r32.6\r\r79.2\r\r67.7\r\r2.8\r\r2.5\r\r5.3\r\r9.4\r\r11.0\r\r10.2\r\r26.5\r\r19.1\r\r8.8\r\r18.5\r\r9.7\r\r7.5\r\r2.3\r\r41.5\r\r3.4\r\r4.9\r\r2.3\r\r17.8\r\r26.7\r\r1.6\r\r10.1\r\r10.0\r\r0.64\r\r80.05\r\r5.0\r\r73.5\r\r31.1\r\r41.7\r\r90.4\r\r140.6\r\r31.4\r\r13.4\r\r127.9\r\r9.4\r\r30.3\r\r5.1\r\r7.3\r\r13.9\r\r20.5\r\r4.56\r\r1564\r\r27\r\r1293.2\r\r3304\r\r12.1\r\r14.5\r\r35\r\r18.2\r\r4015\r\r3296\r\r3693\r\r3844.7\r\r6.0\r\r54.4\r\r28.7\r\r5.8\r\r27.7\r\r0.2\r\r5.0\r\r886.5\r\r383.0\r\r51.7\r\r17.1\r\r31.5\r\r7.3\r\r9.84\r\r295.2\r\r30.1\r\r26.0\r\r74.6\r\r67.8\r\r88.6\r\r34.9\r\r30.2\r\r91.0\r\r67.0\r\r39.6\r\r7.3\r\r399.2\r\r2269.4\r\r74.5\r\r755.3\r\r53.4\r\r1\r\r0\r\r0\r\r1\r\r209\r\r3112\r\r22801\r\r16.9\r\r17.7\r\r17.4\r\r26.2\r\r9.8\r\r12.9\r\r5.25\r\r30.2\r\r146.1\r\r7.31\r\r1.91\r\r6.6\r\r2\r\r64\r\r0\r\r0\r\r0\r\r460\r\r92\r\r415\r\r94\r\r590\r\r89\r\r193\r\r100\r\r436\r\r49.1\r\r30.3\r\r27.1\r\r13.1\r\r4.6\r\r3.4\r\r2.0\r\r1.3\r\r0.9\r\r17.9\r\r2.9\r\r21.0\r\r2.0\r\r120.2\r\r30.6\r\r6.96\r\r45.7\r\r66.4\r\r18.3\r\r30.0\r\r5.9\r\r108.1\r\r7.3\r\r1.7\r\r34.9\r\r91.0\r\r0.0\r\r45821.3\r\r4.6\r\r51.5\r\r26.0\r\r97.5\r\r38.3\r\r48.1\r\r13.6\r\r0.20\r\r0.69\r\r0.14\r\r0.68\r\r0.66\r\r2.37\r\r9.06\r\r31.13\r\r6.29\r\r30.83\r\r30.10\r\r107.42\r\r265.92\r\r0.11\r\r0.00\r\r0.06\r\r0.04\r\r0.33\r\r0.53\r\r0.04\r\r0.11\r\r0.06\r\r0.51\r\r0.33\r\r0\r\r0.21\r\r0.00\r\r0.67\r\r0.00\r\r0.05\r\r0.17\r\r0.56\r\r0.25\r\r0.02\r\r0.04\r\r0.00\r\r0.02\r\r0.61\r\r1.34\r\r1.35\r\r0.81\r\r0\r\r0.00\r\r0.93\r\r0.17\r\r0.08\r\r1.10\r\r0.01\r\r0.16\r\r0.06\r\r0.04\r\r10.75\r\r4.85\r\r0.00\r\r2.83\r\r1.62\r\r14.95\r\r23.83\r\r2.02\r\r4.85\r\r2.83\r\r23.03\r\r14.95\r\r0\r\r9.70\r\r0.00\r\r30.30\r\r0.00\r\r2.42\r\r7.68\r\r25.45\r\r11.31\r\r0.81\r\r1.62\r\r0.00\r\r0.81\r\r27.47\r\r60.59\r\r61.40\r\r36.76\r\r0\r\r0.00\r\r42.01\r\r7.68\r\r3.64\r\r49.69\r\r0.40\r\r7.27\r\r2.83\r\r1.62\r\r487.18\r\r1206\r\r0\r\r0\r\r0.00\r\r0\r\r0.02\r\r0.04\r\r0.00\r\r0.01\r\r0\r\r0.05\r\r0.04\r\r0\r\r0.01\r\r0\r\r0.09\r\r0\r\r0\r\r0.01\r\r0.05\r\r0.01\r\r0\r\r0\r\r0\r\r0\r\r0.06\r\r0.21\r\r0.29\r\r0.13\r\r0\r\r0\r\r0.10\r\r0.01\r\r0\r\r0.20\r\r0\r\r0.10\r\r0\r\r0\r\r0.30\r\r6862\r\r\r\r43.20\r\r10.73\r\r53.87\r\r108\r\rSchleswig-Holstein\r\r217198\r\r8.6\r\r69.7\r\r26.5\r\r7.0\r\r8.6\r\r35.7\r\r17.2\r\r58.0\r\r8.5\r\r36.3\r\r176.7\r\r18.6\r\r52.5\r\r75.6\r\r24.3\r\r40.5\r\r56.1\r\r18.5\r\r48.4\r\r21.0\r\r46.9\r\r17.6\r\r31.9\r\r81.1\r\r85.6\r\r2.7\r\r2.5\r\r5.2\r\r10.0\r\r8.2\r\r7.0\r\r25.0\r\r21.5\r\r10.5\r\r23.2\r\r12.7\r\r9.6\r\r3.1\r\r44.7\r\r2.2\r\r6.0\r\r3.1\r\r19.5\r\r36.1\r\r1.7\r\r9.1\r\r12.7\r\r0.72\r\r79.62\r\r1.0\r\r70.7\r\r54.5\r\r43.0\r\r104.4\r\r49.2\r\r22.7\r\r16.3\r\r60.1\r\r10.0\r\r25.6\r\r4.6\r\r11.1\r\r12.8\r\r14.2\r\r2.81\r\r163\r\r2593\r\r1298.6\r\r3036\r\r15.1\r\r17.0\r\r26859\r\r23.9\r\r3784\r\r3055\r\r3324\r\r2718.6\r\r5.7\r\r37.1\r\r56.8\r\r15.4\r\r152.6\r\r1.7\r\r16.8\r\r2028.8\r\r442.1\r\r52.6\r\r19.6\r\r27.3\r\r16.0\r\r9.15\r\r393.9\r\r20.5\r\r36.0\r\r120.0\r\r44.7\r\r156.1\r\r34.3\r\r22.3\r\r92.3\r\r61.7\r\r35.4\r\r6.8\r\r375.7\r\r3039.8\r\r106.4\r\r724.8\r\r36.9\r\r1\r\r0\r\r0\r\r1\r\r101\r\r1454\r\r22491\r\r16.1\r\r25.6\r\r16.5\r\r31.0\r\r9.3\r\r20.1\r\r6.82\r\r26.6\r\r132.3\r\r6.25\r\r1.89\r\r5.7\r\r3\r\r9\r\r0\r\r0\r\r0\r\r532\r\r90\r\r707\r\r82\r\r705\r\r88\r\r276\r\r99\r\r444\r\r43.6\r\r31.3\r\r17.9\r\r15.0\r\r3.9\r\r3.0\r\r1.6\r\r0.7\r\r0.6\r\r43.2\r\r7.8\r\r19.7\r\r2.4\r\r109.0\r\r27.1\r\r5.13\r\r38.0\r\r65.3\r\r17.8\r\r26.6\r\r5.8\r\r87.4\r\r11.1\r\r2.0\r\r34.3\r\r92.3\r\r100.0\r\r38078.1\r\r4.0\r\r56.1\r\r29.2\r\r95.9\r\r37.0\r\r48.1\r\r14.8\r\r0.25\r\r0.18\r\r0.23\r\r0.44\r\r0.45\r\r1.54\r\r24.51\r\r17.43\r\r22.51\r\r42.43\r\r43.38\r\r150.27\r\r326.38\r\r0.02\r\r0.01\r\r0.31\r\r0.00\r\r0.75\r\r0.62\r\r0.07\r\r0.03\r\r0.01\r\r0.44\r\r0.09\r\r0\r\r0.16\r\r0.02\r\r0.35\r\r0.00\r\r0.02\r\r0.17\r\r0.46\r\r0.51\r\r0.00\r\r0.05\r\r0.07\r\r0.04\r\r0.26\r\r1.23\r\r0.88\r\r0.48\r\r0\r\r0.05\r\r0.50\r\r0.11\r\r0.06\r\r0.79\r\r0.00\r\r0.01\r\r0.02\r\r0.00\r\r8.62\r\r2.30\r\r0.92\r\r30.39\r\r0.46\r\r73.21\r\r60.77\r\r6.91\r\r3.22\r\r1.38\r\r42.82\r\r9.21\r\r0\r\r15.65\r\r1.84\r\r34.53\r\r0.00\r\r2.30\r\r16.11\r\r45.12\r\r49.26\r\r0.00\r\r4.60\r\r6.45\r\r3.68\r\r25.78\r\r120.17\r\r86.10\r\r46.96\r\r0\r\r4.60\r\r48.80\r\r10.59\r\r5.52\r\r77.35\r\r0.46\r\r0.92\r\r1.84\r\r0.00\r\r840.25\r\r1825\r\r0\r\r0\r\r0.02\r\r0\r\r0.04\r\r0.04\r\r0.00\r\r0.00\r\r0\r\r0.06\r\r0.00\r\r0\r\r0.01\r\r0\r\r0.03\r\r0\r\r0\r\r0.01\r\r0.03\r\r0.04\r\r0\r\r0\r\r0\r\r0\r\r0.01\r\r0.23\r\r0.10\r\r0.08\r\r0\r\r0\r\r0.04\r\r0.00\r\r0\r\r0.14\r\r0\r\r0.00\r\r0\r\r0\r\r0.13\r\r6487\r\r\r\r31.48\r\r9.98\r\r54.08\r\r108\r\rSchleswig-Holstein\r\r79487\r\r9.2\r\r75.6\r\r25.8\r\r9.5\r\r11.5\r\r48.9\r\r17.9\r\r63.7\r\r8.9\r\r38.3\r\r100.6\r\r12.5\r\r9.7\r\r81.8\r\r18.1\r\r43.1\r\r56.2\r\r19.5\r\r50.5\r\r21.2\r\r46.2\r\r16.9\r\r27.2\r\r82.1\r\r78.1\r\r2.7\r\r2.6\r\r5.3\r\r11.3\r\r8.2\r\r6.5\r\r24.3\r\r21.8\r\r10.4\r\r22.6\r\r12.2\r\r9.4\r\r2.8\r\r44.2\r\r3.1\r\r5.2\r\r4.5\r\r21.0\r\r35.3\r\r1.0\r\r8.9\r\r14.4\r\r0.71\r\r78.65\r\r4.3\r\r66.0\r\r62.3\r\r39.6\r\r99.0\r\r0.0\r\r0.0\r\r16.1\r\r0.0\r\r11.3\r\r29.8\r\r6.0\r\r7.2\r\r15.0\r\r6.9\r\r0.92\r\r1572\r\r2464\r\r1316.4\r\r2842\r\r17.9\r\r21.6\r\r42238\r\r14.9\r\r3433\r\r2872\r\r3012\r\r2184.3\r\r5.3\r\r50.7\r\r48.2\r\r4.5\r\r40.5\r\r0.5\r\r6.0\r\r7671.7\r\r563.9\r\r55.4\r\r23.8\r\r32.8\r\r7.5\r\r8.62\r\r448.4\r\r23.8\r\r30.4\r\r126.6\r\r51.9\r\r158.6\r\r29.3\r\r13.0\r\r85.5\r\r40.1\r\r62.2\r\r7.6\r\r337.3\r\r1650.6\r\r35.2\r\r775.4\r\r3.5\r\r2\r\r0\r\r0\r\r1\r\r1108\r\r1645\r\r26087\r\r15.6\r\r21.3\r\r17.5\r\r22.5\r\r8.5\r\r16.1\r\r8.62\r\r25.2\r\r133.9\r\r7.76\r\r1.99\r\r6.4\r\r7\r\r47\r\r0\r\r0\r\r0\r\r588\r\r85\r\r645\r\r82\r\r682\r\r81\r\r187\r\r100\r\r514\r\r54.5\r\r38.6\r\r25.9\r\r14.7\r\r4.4\r\r3.6\r\r1.6\r\r1.6\r\r1.4\r\r13.9\r\r2.4\r\r26.6\r\r2.1\r\r129.8\r\r31.3\r\r5.06\r\r39.5\r\r61.9\r\r17.5\r\r25.0\r\r4.8\r\r70.6\r\r7.2\r\r2.4\r\r29.3\r\r85.5\r\r100.0\r\r39620.9\r\r4.5\r\r56.2\r\r27.7\r\r97.9\r\r34.7\r\r48.2\r\r17.1\r\r0.13\r\r0.11\r\r0.30\r\r0.43\r\r0.56\r\r1.52\r\r11.25\r\r9.52\r\r26.65\r\r38.50\r\r50.19\r\r136.11\r\r108.19\r\r0.01\r\r0.00\r\r0.00\r\r0.00\r\r0.03\r\r0.27\r\r0.03\r\r0.01\r\r0.01\r\r0.13\r\r0.00\r\r0\r\r0.06\r\r0.01\r\r0.10\r\r0.01\r\r0.03\r\r0.01\r\r0.25\r\r0.06\r\r0.00\r\r0.01\r\r0.00\r\r0.01\r\r0.32\r\r0.56\r\r0.24\r\r0.21\r\r0\r\r0.00\r\r0.32\r\r0.03\r\r0.01\r\r0.13\r\r0.03\r\r0.03\r\r0.03\r\r0.00\r\r2.96\r\r1.26\r\r0.00\r\r0.00\r\r0.00\r\r2.52\r\r23.90\r\r2.52\r\r1.26\r\r1.26\r\r11.32\r\r0.00\r\r0\r\r5.03\r\r1.26\r\r8.81\r\r1.26\r\r2.52\r\r1.26\r\r22.65\r\r5.03\r\r0.00\r\r1.26\r\r0.00\r\r1.26\r\r28.94\r\r50.32\r\r21.39\r\r18.87\r\r0\r\r0.00\r\r28.94\r\r2.52\r\r1.26\r\r11.32\r\r2.52\r\r2.52\r\r2.52\r\r0.00\r\r265.45\r\r211\r\r0\r\r0\r\r0.00\r\r0\r\r0.00\r\r0.05\r\r0.00\r\r0.00\r\r0\r\r0.05\r\r0.00\r\r0\r\r0.00\r\r0\r\r0.02\r\r0\r\r0\r\r0.00\r\r0.05\r\r0.00\r\r0\r\r0\r\r0\r\r0\r\r0.13\r\r0.16\r\r0.08\r\r0.09\r\r0\r\r0\r\r0.17\r\r0.00\r\r0\r\r0.04\r\r0\r\r0.04\r\r0\r\r0\r\r0.10\r\r3521\r\r\r\r19.75\r\r9.11\r\r54.13\r\r108\r\rSchleswig-Holstein\r\r133210\r\r6.8\r\r55.4\r\r19.3\r\r7.6\r\r13.7\r\r43.0\r\r17.8\r\r41.3\r\r6.3\r\r30.5\r\r52.5\r\r9.3\r\r16.6\r\r94.1\r\r5.8\r\r54.3\r\r55.8\r\r19.7\r\r45.2\r\r23.3\r\r50.1\r\r16.1\r\r30.0\r\r81.1\r\r130.9\r\r2.4\r\r2.4\r\r4.8\r\r11.2\r\r7.8\r\r5.2\r\r22.6\r\r23.8\r\r11.9\r\r24.6\r\r12.7\r\r9.9\r\r2.8\r\r45.8\r\r0.4\r\r6.1\r\r2.4\r\r20.5\r\r39.2\r\r4.6\r\r8.0\r\r13.3\r\r0.77\r\r79.28\r\r3.7\r\r72.2\r\r23.1\r\r38.6\r\r99.3\r\r13.7\r\r13.7\r\r19.7\r\r17.5\r\r11.2\r\r27.8\r\r3.6\r\r8.6\r\r12.7\r\r6.8\r\r0.96\r\r1793\r\r2317\r\r1260.8\r\r2914\r\r12.8\r\r17.3\r\r36985\r\r13.7\r\r3343\r\r2924\r\r3248\r\r844.5\r\r0.5\r\r11.1\r\r58.6\r\r3.8\r\r402.7\r\r10.2\r\r9.5\r\r1607.3\r\r518.4\r\r46.1\r\r25.3\r\r21.7\r\r0.0\r\r5.26\r\r411.9\r\r23.6\r\r28.8\r\r125.9\r\r43.7\r\r130.8\r\r20.6\r\r2.9\r\r85.1\r\r7.9\r\r54.4\r\r8.3\r\r366.3\r\r1831.6\r\r53.4\r\r824.7\r\r7.9\r\r2\r\r74\r\r2\r\r0\r\r93\r\r122\r\r11103\r\r11.8\r\r13.2\r\r19.9\r\r20.2\r\r6.9\r\r24.2\r\r5.35\r\r19.1\r\r94.6\r\r7.64\r\r1.91\r\r6.1\r\r14\r\r71\r\r19\r\r65\r\r14\r\r1864\r\r51\r\r248\r\r41\r\r1823\r\r50\r\r576\r\r87\r\r583\r\r70.8\r\r73.5\r\r-15.8\r\r16.7\r\r4.0\r\r3.1\r\r-0.1\r\r0.5\r\r0.5\r\r84.3\r\r11.7\r\r2.6\r\r4.9\r\r91.7\r\r16.0\r\r1.77\r\r31.4\r\r70.1\r\r11.8\r\r18.9\r\r2.5\r\r47.2\r\r8.6\r\r1.9\r\r20.6\r\r85.1\r\r63.0\r\r31456.6\r\r2.8\r\r55.8\r\r26.3\r\r71.8\r\r32.9\r\r47.4\r\r19.7\r\r0.04\r\r0.01\r\r0.08\r\r0.28\r\r0.25\r\r0.65\r\r41.70\r\r6.89\r\r90.28\r\r297.00\r\r262.48\r\r698.35\r\r930.27\r\r0.00\r\r0.00\r\r0.01\r\r0.00\r\r0.02\r\r0.03\r\r0.00\r\r0.00\r\r0.00\r\r0.02\r\r0.00\r\r0\r\r0.01\r\r0.00\r\r0.06\r\r0.00\r\r0.00\r\r0.01\r\r0.01\r\r0.02\r\r0.00\r\r0.01\r\r0.00\r\r0.00\r\r0.02\r\r0.07\r\r0.04\r\r0.03\r\r0\r\r0.00\r\r0.05\r\r0.01\r\r0.00\r\r0.04\r\r0.00\r\r0.01\r\r0.00\r\r0.00\r\r0.45\r\r4.50\r\r0.00\r\r6.01\r\r0.75\r\r18.77\r\r28.53\r\r1.50\r\r0.75\r\r1.50\r\r25.52\r\r4.50\r\r0\r\r6.01\r\r0.00\r\r60.06\r\r0.00\r\r0.00\r\r12.01\r\r9.01\r\r19.52\r\r0.75\r\r7.51\r\r0.75\r\r1.50\r\r20.27\r\r78.82\r\r37.53\r\r27.78\r\r0\r\r0.00\r\r52.55\r\r6.01\r\r4.50\r\r38.29\r\r0.00\r\r6.01\r\r0.00\r\r0.00\r\r481.20\r\r641\r\r0\r\r0\r\r0.00\r\r0\r\r0.00\r\r0.00\r\r0.00\r\r0.00\r\r0\r\r0.00\r\r0.00\r\r0\r\r0.00\r\r0\r\r0.02\r\r0\r\r0\r\r0.00\r\r0.00\r\r0.00\r\r0\r\r0\r\r0\r\r0\r\r0.00\r\r0.03\r\r0.01\r\r0.00\r\r0\r\r0\r\r0.01\r\r0.00\r\r0\r\r0.01\r\r0\r\r0.00\r\r0\r\r0\r\r0.01\r\r4041\r\r\r\r54.83\r\r10.60\r\r53.59\r\r108\r\rSchleswig-Holstein\r\r197264\r\r5.5\r\r44.9\r\r22.6\r\r6.4\r\r11.4\r\r32.3\r\r22.3\r\r44.5\r\r6.3\r\r35.9\r\r114.1\r\r22.7\r\r19.5\r\r90.7\r\r9.2\r\r47.5\r\r58.2\r\r20.0\r\r51.2\r\r19.8\r\r45.4\r\r17.1\r\r32.5\r\r82.1\r\r136.0\r\r2.8\r\r2.8\r\r5.6\r\r11.8\r\r6.8\r\r4.9\r\r24.9\r\r23.8\r\r10.2\r\r22.3\r\r12.0\r\r9.3\r\r2.8\r\r44.6\r\r4.3\r\r6.1\r\r2.5\r\r22.2\r\r35.0\r\r8.3\r\r9.1\r\r12.1\r\r0.87\r\r80.58\r\r3.9\r\r76.8\r\r10.3\r\r36.3\r\r100.1\r\r0.0\r\r0.0\r\r16.7\r\r0.0\r\r11.8\r\r22.5\r\r4.0\r\r9.6\r\r10.8\r\r10.6\r\r1.11\r\r1903\r\r2404\r\r1257.6\r\r2832\r\r10.1\r\r11.7\r\r54979\r\r20.9\r\r3404\r\r287\r\r3031\r\r1344.4\r\r0.9\r\r11.5\r\r59.8\r\r26.0\r\r1673.3\r\r3.3\r\r5.0\r\r2476.9\r\r490.2\r\r47.9\r\r23.3\r\r19.9\r\r12.7\r\r3.14\r\r406.7\r\r25.6\r\r28.4\r\r111.1\r\r56.2\r\r126.2\r\r31.7\r\r19.2\r\r83.1\r\r38.5\r\r40.9\r\r7.5\r\r474.9\r\r1251.8\r\r52.9\r\r791.1\r\r1.6\r\r2\r\r36\r\r3\r\r0\r\r155\r\r193\r\r35799\r\r8.6\r\r10.3\r\r27.4\r\r13.0\r\r7.8\r\r14.9\r\r4.62\r\r13.5\r\r71.8\r\r7.77\r\r2.02\r\r6.9\r\r10\r\r30\r\r20\r\r31\r\r13\r\r1545\r\r63\r\r2042\r\r49\r\r1804\r\r48\r\r343\r\r94\r\r572\r\r71.7\r\r79.7\r\r-52.4\r\r15.6\r\r4.1\r\r2.9\r\r-0.5\r\r0.2\r\r0.3\r\r23.6\r\r3.4\r\r4.9\r\r3.2\r\r94.4\r\r15.0\r\r1.85\r\r21.7\r\r61.0\r\r9.1\r\r13.4\r\r2.6\r\r41.8\r\r9.6\r\r1.7\r\r31.7\r\r83.1\r\r71.7\r\r21795.1\r\r2.6\r\r58.2\r\r27.4\r\r92.6\r\r27.3\r\r47.7\r\r25.1\r\r0.09\r\r0.01\r\r0.14\r\r0.24\r\r0.30\r\r0.78\r\r58.77\r\r5.10\r\r90.62\r\r153.91\r\r193.65\r\r502.04\r\r990.34\r\r0.01\r\r0.00\r\r0.01\r\r0.00\r\r0.04\r\r0.10\r\r0.00\r\r0.00\r\r0.00\r\r0.01\r\r0.00\r\r0\r\r0.01\r\r0.00\r\r0.03\r\r0.00\r\r0.00\r\r0.01\r\r0.03\r\r0.02\r\r0.01\r\r0.01\r\r0.00\r\r0.00\r\r0.03\r\r0.11\r\r0.05\r\r0.05\r\r0\r\r0.00\r\r0.06\r\r0.01\r\r0.00\r\r0.04\r\r0.00\r\r0.01\r\r0.00\r\r0.00\r\r0.69\r\r3.55\r\r0.00\r\r9.12\r\r0.00\r\r24.33\r\r64.38\r\r1.52\r\r0.51\r\r1.52\r\r8.11\r\r2.53\r\r0\r\r4.06\r\r0.51\r\r18.76\r\r0.00\r\r1.01\r\r8.62\r\r19.77\r\r14.70\r\r6.08\r\r7.60\r\r0.51\r\r1.01\r\r20.78\r\r70.97\r\r32.95\r\r31.94\r\r0\r\r2.03\r\r39.03\r\r8.11\r\r3.04\r\r27.37\r\r0.51\r\r3.55\r\r1.01\r\r0.00\r\r439.51\r\r867\r\r0\r\r0\r\r0.00\r\r0\r\r0.00\r\r0.02\r\r0.00\r\r0.00\r\r0\r\r0.00\r\r0.00\r\r0\r\r0.00\r\r0\r\r0.00\r\r0\r\r0\r\r0.00\r\r0.00\r\r0.00\r\r0\r\r0\r\r0\r\r0\r\r0.00\r\r0.02\r\r0.01\r\r0.01\r\r0\r\r0\r\r0.01\r\r0.00\r\r0\r\r0.01\r\r0\r\r0.00\r\r0\r\r0\r\r0.01\r\r4296\r\r\r\r\rThe first column (AdjRate) contains age-adjusted incidence rates. The X and Y coordinates (longitude and latitude) contain the spatial information. The NUTS2 code represents the government regions (Regierungsbezirke) ID, BL_ID contains the name of the federal state (Bundesland) and EWZ refers to the population count. After that follows a ton of socioeconomic, infrastructural, and built environment characteristics. We will thin out the important features later and talk about their meaning, so don’t worry about the coding of the variables.\nBART needs a data.frame of predictors and a vector of the response variable.\npsych::skew(data$AdjRate)\r## [1] 3.64179\r# Response variable\ry \u0026lt;- log(data$AdjRate)\r# Data.frame of predictors\rdata_bm \u0026lt;- select(data, -c(AdjRate))\rAdjRate is highly skewed (skewness = 3.64) and was therefore log-transformed. The results from the BART machine won’t differ with the highly skewed data, since it is non-parametric. However, to improve visual interpretability, we will use the log-rate in all the figures.\nBelow I have printed the summary statistics of the AdjRate (log), to understand the model outputs.\n\r\rMean\r\rSD\r\rMin\r\rMax\r\r\r\r\r\r4.13\r\r0.7\r\r1.75\r\r6.51\r\r\r\r\r\rFirst BART model\rIt would be fine to use the default values for the hyperparameter (e.g. number of trees), however bartMachine comes with a simple function to compute optimal hyperparameters, called bartMachineCV. This will take quite some time to run! Therefore I have excluded this function from the script and just build a bartMachine with the optimal parameters.\nbm_All \u0026lt;- bartMachine(X = data_bm, y = y, k=2, nu=3, q=0.9, num_trees=100, num_iterations_after_burn_in=2000, num_burn_in = 300, seed = 1234, verbose = FALSE)\r## Warning in build_bart_machine(X, y, Xy, num_trees, num_burn_in, num_iterations_after_burn_in, : Setting the seed when using parallelization does not result in deterministic output.\r## If you need deterministic output, you must run \u0026quot;set_bart_machine_num_cores(1)\u0026quot; and then build the BART model with the set seed.\rsummary(bm_All)\r## bartMachine v1.2.6 for regression\r## ## training data n = 401 and p = 366 ## built in 7.3 secs on 20 cores, 100 trees, 300 burn-in and 2000 post. samples\r## ## sigsq est for y beforehand: 0.024 ## avg sigsq estimate after burn-in: 0.08411 ## ## in-sample statistics:\r## L1 = 56.04 ## L2 = 13.1 ## rmse = 0.18 ## Pseudo-Rsq = 0.9323\r## p-val for shapiro-wilk test of normality of residuals: 0.00087 ## p-val for zero-mean noise: 0.96076\rThe Pseudo-R² of 0.93 and RMSE of 0.18 look quiet promising, but let’s check for error assumptions.\ncheck_bart_error_assumptions(bm_All)\rBoth plots look good. In the second one (Assessment of Heteroskedasticity) we can detect a visible pattern - however not a prominent one! From both plots I would assume that the overall performance of the model is good, however it might struggle with extreme values.\nplot_y_vs_yhat(bm_All, credible_intervals = TRUE)\rThe “Fitted vs. Actual Values” plot above indicates overall good model performance. Again, we can see that the model struggles with extreme values. Low values will be over-predicted and high values will be under-predicted. We could also map the residuals geographically and see, if there is spatial clustering. But first, we will reduce the model complexity by removing non-important variables.\n\rVariable Selection\rBART is quiet a powerful machine learning tool, but there is more to it than amazing R² values! If you are dealing with a high dimensional data set (like our data with 313 predictors), often only a relatively small subset of predictor variables truly influences the response variable. Occam’s razor describes this philosophy, that simpler models should be preferred to unnecessarily complex ones.\nThe var_selection_by_permute function performs variable selection introduced by Bleich et al. (2014), to reduce model complexity. Let’s run the next chunk and investigate the most important variables. You may skip this step and just use my results, as this will take quiet long to run…\n# Leave the num_trees_for_permute small, to force variables to compete for entry into the model!\rvar_sel \u0026lt;- bartMachine::var_selection_by_permute_cv(bm_All, num_trees_for_permute = 20)\r# Look at the most important variables\rvar_sel$important_vars_cv\r## [1] \u0026quot;BL_ID_Baden-Württemberg\u0026quot; \u0026quot;BL_ID_Bayern\u0026quot; ## [3] \u0026quot;BL_ID_Hessen\u0026quot; \u0026quot;ff_pop\u0026quot; ## [5] \u0026quot;hair_pp\u0026quot; \u0026quot;thea_pp\u0026quot; ## [7] \u0026quot;NUTS2_Fact_11\u0026quot; \u0026quot;NUTS2_Fact_27\u0026quot; ## [9] \u0026quot;NUTS2_Fact_40\u0026quot; \u0026quot;NUTS2_Fact_71\u0026quot; ## [11] \u0026quot;S_170\u0026quot; \u0026quot;play_dn\u0026quot; ## [13] \u0026quot;bir_km2\u0026quot; \u0026quot;cc_pop\u0026quot; ## [15] \u0026quot;sch_den\u0026quot; \u0026quot;kid_den\u0026quot; ## [17] \u0026quot;Rch_den\u0026quot; \u0026quot;S_109_2\u0026quot; ## [19] \u0026quot;EWZ\u0026quot; \u0026quot;Pop_Den\u0026quot; ## [21] \u0026quot;S_004\u0026quot; \u0026quot;S_006\u0026quot; ## [23] \u0026quot;S_020\u0026quot; \u0026quot;S_051\u0026quot; ## [25] \u0026quot;S_054\u0026quot; \u0026quot;S_066\u0026quot; ## [27] \u0026quot;S_070\u0026quot; \u0026quot;S_080\u0026quot; ## [29] \u0026quot;S_104\u0026quot; \u0026quot;S_107\u0026quot; ## [31] \u0026quot;S_115\u0026quot; \u0026quot;S_123\u0026quot; ## [33] \u0026quot;S_130\u0026quot; \u0026quot;S_146\u0026quot; ## [35] \u0026quot;S_153\u0026quot; \u0026quot;X\u0026quot; ## [37] \u0026quot;Y\u0026quot;\rBelow I have categorized the important variables, that will be used for the second BART model. Also I have removed the NUTS2_Fact and BL_ID variables.\ndata_subset \u0026lt;- data_bm %\u0026gt;%\rselect(c(\r# Geographical Units\rX, #Longitude\rY, #Latitude\r# Political units\rS_109, #Rural/Urban\r# Socioeconomic\rEWZ, #Population\rPop_Den, #Population density\rS_004, #Unemployment rate under 25\rS_006, #Household income per capita S_020, #Employment rate 15-\u0026lt;30\rS_051, #Voter participation\rS_054, #Apprenticeship positions\rS_066, #Household income\rS_070, #Deptors rate\rS_080, #Recreationl Space\rS_104, #Income tax\rS_107, #Steuerkraft\rS_115, #Regional population potential\rS_123, #Child poverty\rS_130, #IC train station access\rS_146, #Commuters \u0026gt;150km\rS_153, #Foreign guests in tourist establishments\rS_170, #Longterm unemployment rate\r# Built environment\rRch_den, #Church density\rplay_dn, #Playground density\rbir_km2, #Biergarten per km²\rff_pop, #Fast food places per capita\rhair_pp, #Hairdresser per capita\rthea_pp, #Theatre per capita\rcc_pop, #Community centre density\rsch_den, #School density\rkid_den #Kindergarten density\r))\r\rSecond BART model\rWith the subset of important predictors, we will build a second BART model. Again, I have already computed the optimal hyperparameters using the bartMachineCV function.\nbm_final \u0026lt;- bartMachine(X = data_subset, y = y, k=3, nu=3, q=0.99, num_trees=225,\rseed = 1234, verbose = FALSE)\r## Warning in build_bart_machine(X, y, Xy, num_trees, num_burn_in, num_iterations_after_burn_in, : Setting the seed when using parallelization does not result in deterministic output.\r## If you need deterministic output, you must run \u0026quot;set_bart_machine_num_cores(1)\u0026quot; and then build the BART model with the set seed.\rsummary(bm_final)\r## bartMachine v1.2.6 for regression\r## ## training data n = 401 and p = 31 ## built in 5 secs on 20 cores, 225 trees, 250 burn-in and 1000 post. samples\r## ## sigsq est for y beforehand: 0.185 ## avg sigsq estimate after burn-in: 0.12811 ## ## in-sample statistics:\r## L1 = 89.74 ## L2 = 34.06 ## rmse = 0.29 ## Pseudo-Rsq = 0.824\r## p-val for shapiro-wilk test of normality of residuals: 0.00122 ## p-val for zero-mean noise: 0.94939\rCompared to the first BART model, the second one saw a reduction in Pseudo-R² from 0.93 to 0.82, equating to a 12% reduction in explained variability. The RMSE increased from 0.18 to 0.29, indicating that the final model predicted age-adjusted incidence rates of COVID-19 for German counties with an accuracy of +/− 1.3 cases per 100,000. Again we need to check error assumptions and fitted vs. actual values.\ncheck_bart_error_assumptions(bm_final)\rThe new model is expected to perform worse compared to the first model, but the Q-Q and Fitted vs. Residuals plots both look good. Again, the BART model struggles with extreme (high) values.\nplot_y_vs_yhat(bm_final, credible_intervals = TRUE)\rThe “Fitted vs. Actual Values” plot above indicates overall OK model performance. This time however, a larger amount of values are outside of the confidence interval. We will also map the residuals, to test for spatial clustering.\n\rSpatial autocorrelation\rSpatial autocorrelation can be tested by mapping the residuals. I have provided a cleaned shapefile of the NUTS3 (federal states) regions in Germany. The mapped residuals allow us to visualize under- and overpredictions and check for spatial clustering of residuals. From this map I could not detect a discernible pattern of clustering - the residuals are randomly distributed.\nlibrary(sf)\rlibrary(RColorBrewer)\rlibrary(tmap)\r# Download shapefile\rshp \u0026lt;- read_sf(\u0026quot;https://github.com/STBrinkmann/data/raw/main/RKI_sf.gpkg\u0026quot;)\r# Sort shapefile, that it has the same order as the data_subset\rshp \u0026lt;- shp[order(match(shp$EWZ, data_subset$EWZ)),]\r# Join residuals to shapefile, then map residuals\rshp$resid \u0026lt;- bm_final$residuals\rtm_shape(shp) + tm_polygons(col=\u0026quot;resid\u0026quot;, title=\u0026quot;BART Machine Residuals\\n(log incidence rate)\u0026quot;, breaks=seq(-1.75, 1.75, 0.5), midpoint=NA, palette=\u0026quot;RdBu\u0026quot;) + tm_layout(frame = FALSE,\rinner.margins=c(0.02, 0.02, 0.02, 0.20),\rlegend.position = c(0.7, 0.22),\rlegend.frame = TRUE,\rlegend.outside = FALSE, bg.color = \u0026quot;white\u0026quot;)\rTo determine whether the spatial autocorrelation of residuals is statistically significant or not, one could compute Moran’s I. I will not explain Moran’s I in this post, but I would highly recommend these posts: Intro to GIS and Spatial Analysis and Spatial autocorrelation analysis in R.\nlibrary(spdep)\r# Define neighboring polygons\rnb \u0026lt;- poly2nb(shp, queen=TRUE)\r# Assign weights to each neighboring polygon\rlw \u0026lt;- nb2listw(nb, style=\u0026quot;B\u0026quot;, zero.policy=TRUE)\r# Compute Moran\u0026#39;s I statistic using a Monte-Carlo simulation MC \u0026lt;- moran.mc(shp$resid, lw, nsim=99)\rMC\r## ## Monte-Carlo simulation of Moran I\r## ## data: shp$resid ## weights: lw ## number of simulations + 1: 100 ## ## statistic = 0.059486, observed rank = 99, p-value = 0.01\r## alternative hypothesis: greater\rThe Moran’s I score is between -1 and 1, where high (low) values determine positive (negative) spatial autocorrelation and 0 identifies the data is randomly distributed. The Morans’s I statistic of 0.06 (p=0.01) further confirms, that there is no spatial autocorrelation.\n\rPartial Dependence Plots\rIn the previous steps we have build a robust BART machine to predict age-adjusted incidence rates of COVID-19 for German counties. However, as already mentioned in the beginning, I am interested in using BART as a exploratory tool. The high R² indicates, that the model did understand the non-linear relationships of the covariates with the COVID-19 incidence rate. To visualize and explore these relationships, Partial Dependence Plots (PDPs) are a great tool. PDPs are graphical outputs that illustrate the marginal effect of each independent variable on the response variable (Friedman 2002; Scarpone et al. 2017, 2020).\nThe R package pdp provides great tools for computing partial dependence. However it does not support bartMachine. But that’s no problem, as bartMachine also comes with a build in function to generate PDPs. The function in the bartMachine package is called pd_plot. I will demonstrate a PDP and it’s corresponding histogram on the example of S_115 (Regional Population Potential). The values of S_115 are plotted on the x-axis and its marginal effect in incidence rate (log-adjusted) on the y-axis.\n# Set parameters to plot PDP top and histogram bottom\rpar(mfrow = c(2,1))\rpd_plot(bm_final, \u0026quot;S_115\u0026quot;, levs = c(0.0, seq(0, 1, 0.1), 1))\r## ...........\rhist(bm_final$X$S_115, 20, main = \u0026quot;Histogram of the Regional Population Potential\u0026quot;,\rxlab = \u0026quot;Regional Population Potential\u0026quot;)\rThe regional population potential measures the likelihood of direct interactions to occur between inhabitants. The PDP indicates small marginal changes in incidence rates for low values of regional population potential, which can be interpreted as evidence that in counties with a lower probability of human interaction, there is a lower probability of viral contagion. The greatest increase in partial dependence is observed between the 20th and 80th percentiles of regional population potential index scores (14,016 to 47,067), indicating a strong non-linear effect of this variable on incidence rates.\nTo improve visual interpretability in the plot above it would make sense to log-transform the data. However, this is not possible using the build in pd_plot function. Therefore I have slightly rewritten this function to generate a ggplot output instead of a simple base R plot (I have provided the edited function on GitHub). Now we can treat the result as an ggplot2 object, scale the axis, adjust the theme, combine the histogram and PDP in one plot,…\nBelow, I have included the PDPs from our paper, visualizing the partial dependence of the 10 most prevalent variables. The variable importance can be computed using the investigate_var_importance function. Based on the spatial exploratory data analysis, we have separated Germany into a low rate region (LLR) and high rate region (HHR). You can read the description and interpretation of the PDPs here.\n\n\rConclusion\rIn this post I have demonstrated that BART is a powerful machine learning tool for modelling high-dimensional, non-linear data. The BART modelling demonstrated that although many variables can be used as inputs, the majority of variability explained will largely be determined from a small subset of all variables. Opening these black-box models and exploring and interpreting the results is easy and intuitive, by computing PDPs. The PDPs help us to understand the non-linear relationships between the covariates and the response variable.\nIn future posts I will further explore the effectiveness of the variable selection function and demonstrate out-of-sample validation to test for overfitting.\n\rReferences\rBleich, Justin, Adam Kapelner, Edward I. George, and Shane T. Jensen. 2014. “Variable Selection for BART: An Application to Gene Regulation.” The Annals of Applied Statistics 8 (3). https://doi.org/10.1214/14-aoas755.\r\rBreiman, Leo. 2001. “Statistical Modeling: The Two Cultures (with Comments and a Rejoinder by the Author).” Statistical Science 16 (3). https://doi.org/10.1214/ss/1009213726.\r\rChipman, Hugh A., Edward I. George, and Robert E. McCulloch. 2010. “BART: Bayesian additive regressiontrees.” The Annals of Applied Statistics 4 (1): 266–98. https://doi.org/10.1214/09-AOAS285.\r\rFriedman, Jerome H. 2002. “Stochastic Gradient Boosting.” Computational Statistics \u0026amp; Data Analysis 38 (4): 367–78. https://doi.org/10.1016/s0167-9473(01)00065-2.\r\rKapelner, Adam, and Justin Bleich. 2016. “bartMachine: Machine Learning with Bayesian Additive Regression Trees.” Journal of Statistical Software 70 (4). https://doi.org/10.18637/jss.v070.i04.\r\rScarpone, Christopher, Sebastian T. Brinkmann, Tim Große, Daniel Sonnenwald, Martin Fuchs, and Blake Byron Walker. 2020. “A Multimethod Approach for County-Scale Geospatial Analysis of Emerging Infectious Diseases: A Cross-Sectional Case Study of COVID-19 Incidence in Germany.” International Journal of Health Geographics 19 (1). https://doi.org/10.1186/s12942-020-00225-1.\r\rScarpone, Christopher, Margaret G. Schmidt, Chuck E. Bulmer, and Anders Knudby. 2017. “Semi-Automated Classification of Exposed Bedrock Cover in British Columbia’s Southern Mountains Using a Random Forest Approach.” Geomorphology 285 (May): 214–24. https://doi.org/10.1016/j.geomorph.2017.02.013.\r\r\r\r","date":1618876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618926893,"objectID":"163ec89a68bb32cfc2f581267b5289d4","permalink":"/post/bart-a-bayesian-machine-learning-workflow-for-complex-spatial-data/","publishdate":"2021-04-20T00:00:00Z","relpermalink":"/post/bart-a-bayesian-machine-learning-workflow-for-complex-spatial-data/","section":"post","summary":"In our recent publication from 2020 we analyzed COVID-19 incidence rates using a multimethod approach. In this post I will present BART - a Bayesian machine learning algorithm - to model COVID-19 incidence rates.","tags":["Bayesian","Machine learning","COVID-19","R"],"title":"BART - A Bayesian machine learning workflow for complex spatial data","type":"post"},{"authors":[],"categories":[],"content":"     body { text-align: justify}  Exposure to residential greenness or green spaces such as parks or gardens are beneficial for multiple measures of health (Markevych et al. 2017; Labib, Lindley, and Huck 2020). Greenness and greenspace will be used as synonyms henceforth. Greenspace exposure can be categorized into three types: (a) availability, referring to the physical amount of greenspace, (b) accessibility, meaning the spatial proximity to greenspace, and (c) visibility, referring to the visual perception of greenness (Labib, Lindley, and Huck 2020).\nIn our recent publication (in submission) we measured greenness taking a top-down, bird’s eye view approach using remote sensing derived NDVI, to approximate the availability of greenness. Furthermore, we used a distance weighted road network to calculate potential neighborhood exposure models around participants place of residency, therefore also accounting for accessibility.\nThe next step will be, to combine greenness visibility with our potential neighborhood exposure models.\nIn this post, I will therefore demonstrate how to download and prepare all necessary files and methods needed for a visibility analysis. In the first part I demonstrate data acquisition and processing, in the second part I will explain the main functions used for the visibility analysis. My implementation of these methods is very light weighted and fast, while still maintaining high resolution. The functions presented in this post for computing a viewshed based Green Visibility Index (GVI), have also been included in the GVI R package.\nLibraries First load all packages. If one of these packages has not been installed, use the install.packages() function.\nterra is a relatively new R package that replaces the well known raster. I have found terra to work much faster for most tasks.\nlibrary(dplyr) library(sf) library(ggplot2) library(ggthemes) library(terra) library(lidR) library(future) library(data.table)  Data The data is being stored in a different directory than this R project. Therefore I first need to assign my working directory.\nworkdir \u0026lt;- \u0026quot;/media/sebastian/Red/Vancouver\u0026quot; DTM First, we need to download the digital terrain model (DTM) generated from LiDAR data collected in 2013 for the City of Vancouver from the City of Vancouver Open Data Portal.\n# Download DTM as .zip download.file(\u0026quot;https://webtransfer.vancouver.ca/opendata/TIF/DEM_2013_TIF.zip\u0026quot;, destfile = file.path(workdir, \u0026quot;dtm.zip\u0026quot;)) # Unzip unzip(zipfile = file.path(workdir, \u0026quot;dtm.zip\u0026quot;), exdir = \u0026quot;Data\u0026quot;) # Delete .zip unlink(file.path(workdir, \u0026quot;dtm.zip\u0026quot;), recursive = TRUE) DTM \u0026lt;- terra::rast(file.path(workdir, \u0026quot;DEM/DEM_2013.tif\u0026quot;)) plot(DTM)  LiDAR Next, we will load the shapefile for the LiDAR 2013 tiles.\n# Lidar tiles lidar_tiles \u0026lt;- read_sf(\u0026quot;https://opendata.vancouver.ca/explore/dataset/lidar-2013/download/?format=geojson\u0026quot;) %\u0026gt;% st_transform(crs(DTM)) %\u0026gt;% dplyr::select(name, lidar_url) lidar_tiles %\u0026gt;% ggplot() + geom_sf() + theme_map() Each tile of this shapefile contains the tile name and a link, to download the LiDAR data. The total file size of all 168 LiDAR scenes is ~90GB. We will store them in a temporary file and calculate a DSM from the data later. I would highly recommend using parallel computation for this and to do something else while the data is being downloaded.\nlidar_download \u0026lt;- function(x, tmp_dir) { # Download GeoTIFF as .zip download.file(x$lidar_url, destfile = paste0(file.path(tmp_dir, x$name), \u0026quot;.zip\u0026quot;)) # Unzip unzip(zipfile = paste0(file.path(tmp_dir, x$name), \u0026quot;.zip\u0026quot;), exdir = file.path(tmp_dir)) # Delete .zip unlink(paste0(file.path(tmp_dir, x$name), \u0026quot;.zip\u0026quot;), recursive = TRUE) } # Set number of cores and path to tmp_dir cores \u0026lt;- 22 tmp_dir \u0026lt;- file.path(workdir, \u0026quot;Temp\u0026quot;) if (!dir.exists(tmp_dir)) { dir.create(tmp_dir) } # Run function if (cores \u0026gt; 1) { if (Sys.info()[[\u0026quot;sysname\u0026quot;]] == \u0026quot;Windows\u0026quot;) { cl \u0026lt;- parallel::makeCluster(cores) parallel::parApply(cl, lidar_tiles, 1, FUN = lidar_download, tmp_dir = tmp_dir) parallel::stopCluster(cl) } else { split(lidar_tiles, seq(nrow(lidar_tiles))) %\u0026gt;% parallel::mclapply(FUN = lidar_download, tmp_dir = tmp_dir, mc.cores = cores, mc.preschedule = TRUE) } } else { apply(lidar_tiles, 1, FUN = lidar_download, tmp_dir = tmp_dir) } One LiDAR tile has almost no land points and the algorithm can’t process it.\nTherefore, we need to remove it.\nfile.remove(file.path(tmp_dir, \u0026quot;CoV_4850E_54510N.las\u0026quot;)) Next, we can load all LiDAR files with the lidR package (Roussel et al. 2020) and calculate the DSM using the pit-free (Khosravipour et al. 2014) algorithm.\nlidar_catalog \u0026lt;- lidR::readLAScatalog(tmp_dir) crs(lidar_catalog) \u0026lt;- terra::crs(DTM) opt_independent_files(lidar_catalog) \u0026lt;- TRUE # Use future to calculate DSM # Adjust number of cores with the workers parameter. This process is very RAM heavy! plan(multisession, gc = TRUE, workers = 10) # I would recommend to run this code from the console, to visualize the progress. lidar_dsm \u0026lt;- grid_canopy(lidar_catalog, res = 0.5, pitfree(thresholds = c(0, 2, 5, 10, 15, 20), max_edge = c(0, 1.5))) # Save raster and remove variables lidar_dsm %\u0026gt;% terra::rast() %\u0026gt;% terra::writeRaster(filename = file.path(workdir, \u0026quot;DSM/dsm.tif\u0026quot;), format=\u0026quot;GTIFF\u0026quot;) rm(lidar_catalog, lidar_dsm) # Load DSM dsm \u0026lt;- terra::rast(file.path(workdir, \u0026quot;DSM/dsm.tif\u0026quot;)) Let’s take a look on the DSM. We will be using the rayshader package to generate a 2D map.\ndsm_clip \u0026lt;- rast(xmin = 487200, xmax = 487800, ymin = 5455800, ymax = 5456400, crs = crs(dsm), res = 0.5) # Crop DSM and convert to matrix elev_matrix \u0026lt;- dsm %\u0026gt;% crop(dsm_clip) %\u0026gt;% matrix( as.vector(terra::values(.)), nrow = ncol(.), ncol = nrow(.) ) %\u0026gt;% t() library(rayshader) options(\u0026quot;cores\u0026quot; = 16) # Calculate rayshader layers ambmat \u0026lt;- ambient_shade(elev_matrix, multicore = TRUE) raymat \u0026lt;- ray_shade(elev_matrix, lambert = TRUE, multicore = TRUE) # Plot 2D elev_matrix %\u0026gt;% sphere_shade(texture = \u0026quot;unicorn\u0026quot;) %\u0026gt;% add_shadow(raymat, max_darken = 0.5) %\u0026gt;% add_shadow(ambmat, max_darken = 0.1) %\u0026gt;% plot_map() There are some missing values in the raster and at the right edge of the map we can see a “wall.” This is due to the fact, that power lines are being measured by LiDAR, too. Therefore we need to post-process the DSM to smooth the raster and fill empty pixels. We will apply a moving window approach. However, the DSM is too large, to apply focal on the whole raster at once. Therefore we will use the lidar_tiles shapefile from above, to apply smoothing and NA-value filling on subsets of the raster. To avoid edge effects, we first crop the DSM to a buffered LiDAR tile, apply the focal and finally crop the processed DSM to the unbuffered LiDAR tile.\n# Check if processing directory exists. delete_folder \u0026lt;- FALSE proc_dir \u0026lt;- file.path(workdir, \u0026quot;DSM/Proc\u0026quot;) if(!dir.exists(proc_dir)) { delete_folder \u0026lt;- TRUE dir.create(proc_dir) } pb = txtProgressBar(min = 0, max = nrow(lidar_tiles), initial = 0, style = 3) for (i in 1:nrow(lidar_tiles)) { dsm %\u0026gt;% # Crop to buffered tile terra::crop(sf::st_buffer(lidar_tiles[i,], 10)) %\u0026gt;% # Fill NA values terra::focal(3, fun = median, na.only = T) %\u0026gt;% # Smoothing terra::focal(9, fun = median, na.rm = TRUE) %\u0026gt;% # Crop to unbuffered tile terra::crop(lidar_tiles[i,]) %\u0026gt;% terra::writeRaster(filename = file.path(proc_dir, paste0(\u0026quot;dsm_tile_\u0026quot;, i, \u0026quot;.tif\u0026quot;)), format=\u0026quot;GTIFF\u0026quot;) setTxtProgressBar(pb, i) } # Merge raster tiles filled_dsm \u0026lt;- dir(proc_dir, pattern = \u0026quot;dsm_tile_\u0026quot;, full.names = T) %\u0026gt;% lapply(rast) %\u0026gt;% do.call(terra::merge, .) # Delete temp files if (delete_folder) { unlink(proc_dir, recursive = TRUE) } else { unlink(dir(proc_dir, pattern = \u0026quot;dsm_tile_\u0026quot;, full.names = T)) } terra::writeRaster(filled_dsm, format=\u0026quot;GTIFF\u0026quot;, filename = file.path(workdir, \u0026quot;DSM/dsm_filled.tif\u0026quot;)) Now let’s look at the post-processed raster.\n# Crop DSM and convert to matrix elev_matrix \u0026lt;- filled_dsm %\u0026gt;% crop(dsm_clip) %\u0026gt;% matrix( as.vector(terra::values(.)), nrow = ncol(.), ncol = nrow(.) ) %\u0026gt;% t() # Calculate rayshader layers ambmat \u0026lt;- ambient_shade(elev_matrix, multicore = TRUE) raymat \u0026lt;- ray_shade(elev_matrix, lambert = TRUE, multicore = TRUE) # Plot 2D elev_matrix %\u0026gt;% sphere_shade(texture = \u0026quot;unicorn\u0026quot;) %\u0026gt;% add_shadow(raymat, max_darken = 0.5) %\u0026gt;% add_shadow(ambmat, max_darken = 0.1) %\u0026gt;% plot_map() The DSM is a lot smoother than before. I have tested multiple different parameters for the smoothing-step and w=9 returned the best looking results. In the future I may apply the smoothing-step only on raster cells covered by power lines.\n  Visibility Analysis Greenspace is associated with several health benefits along multiple pathways (Markevych et al. 2017; Dzhambov et al. 2020; Labib, Lindley, and Huck 2020). In a recent study (in submission), we analyze health benefits based on the availability and accessibility of greenspace, using a top-down, bird’s eye view, approach. Visibility describes a third type of exposure assessment and refers to the amount of greenspace that can be seen from a given point (Labib, Lindley, and Huck 2020). Recent studies have adopted viewshed-based visibility analysis (Chamberlain and Meitner 2013; Tabrizian et al. 2020; Labib, Huck, and Lindley 2021), however there still is a limited use of visibility exposure assessment in current studies (Labib, Lindley, and Huck 2020). The following code is primarily based on the methods described by Labib, Huck, and Lindley (2021) and their Python code of the Green Visibility Index, and the overall process is illustrated in the figure below.\n\nConceptual design of greenspace visibility modelling (Labib, Huck, and Lindley 2021).\nThe line of sight is being calculated from the observer to every point in the area of interest, to distinguish between visible and invisible points. To determine green and no-green points, a greenspace mask will be intersected. To make the code presented in this post easier to understand, it has not been fully optimized. I have created the R package GVI, where I implemented the same functions with optimized data structures and heavy use of C++ code.\nRasterprofile To calculate the visibility of a point B from point A, we first need to access all raster cells from point A to B. The rasterprofile function returns a matrix with all cells from A to B, containing X- and Y-coordinates, the height and the cell-number for every cell. Surprisingly the raster::extract is faster than terra::extract when using a matrix.\nrasterprofile \u0026lt;- function(r, x0, y0, x1, y1, resolution){ # Sample a raster along a straight line between two points # Try to match the sampling size to the raster resolution dx = sqrt((x0 - x1)^2 + (y0 - y1)^2) nsteps = 1 + round(dx / resolution) pointsZ \u0026lt;- cbind(x0 + (0:nsteps) * (x1 - x0) / nsteps, y0 + (0:nsteps) * (y1 - y0) / nsteps) rasterVals \u0026lt;- raster::extract(x = r, y = pointsZ, cellnumber = TRUE) pointsZ \u0026lt;- cbind(pointsZ, rasterVals[,2], rasterVals[,1]) if (anyNA(pointsZ)) { pointsZ \u0026lt;- pointsZ[stats::complete.cases(pointsZ),,drop = FALSE] } return(pointsZ) }  Line of Sight The observer at point A can only see point B, if no object in between point A and B blocks the view to point B. The lineOfSight function evaluates visibility along all cells from A to B, by calculating tangent ⍺ from 𝚫height (opposite side) and distance traveled (adjacent side) and comparing it for every step. To see a point, its tangent ⍺ must be greater than the biggest tangent ⍺ so far.\nIn R we would write a for loop and compare the tangent of the current point to the maximum tangent so far. Therefore this step can’t be vectorised, because the subsequent iterations depend on previous ones. Native R code is quiet “slow” for these kind of tasks. Therefore I have implemented this step in C++ using the Rcpp package.\n#include \u0026lt;Rcpp.h\u0026gt; using namespace Rcpp; // [[Rcpp::export]] NumericVector isVisibleC(NumericVector x) { int n = x.size(); NumericVector out(n); out[0] = 1; double max_tangent = -9999; for(int i = 1; i \u0026lt; n; ++i) { double this_tangent = x[i]; if (this_tangent \u0026gt; max_tangent) { max_tangent = this_tangent; out[i] = 1; } else { out[i] = -1; } } return out; } The lineOfSight function returns a data.table containing the cell number and corresponding visibility of all points from A to B. Visible cells have a value of 1 and non visible cells -1.\nlineOfSight \u0026lt;- function(xy1, x0, y0, height0, resolution, dsm_data) { # Get start XY from input x1 \u0026lt;- xy1[1] y1 \u0026lt;- xy1[2] # Get the pixels in the line pixels \u0026lt;- rasterprofile(r = dsm_data, x0 = x0, y0 = y0, x1 = x1, y1 = y1, resolution = resolution) # Distance traveled so far distance_traveled = sqrt((y0 - pixels[,2])^2 + (x0 - pixels[,1])^2) # Calculate tangent from delta height (opposite side) and distance traveled (adjacent side) tangents \u0026lt;- (pixels[,3] - height0) / (distance_traveled * resolution) # Is visible? Current tangent must be greater than max. tangent visibility \u0026lt;- isVisibleC(tangents) # Return cellnumber and visibility-value data.table::as.data.table(cbind(pixels[,4], visibility)) }  Viewshed Finally, the visibility of all points withing a certain buffer around point A can be calculated, using the lineOfSight function. The viewshed function returns a circular raster (start point + max_distance-buffer) where values of 1 indicate visible points and -1 non-visible points. To calculate visibility for all points in the raster, we only need to calculate the line of sight from the center to all boundary points of the circle and store the information of each point in between.\nviewshed \u0026lt;- function(sf_start, max_distance, dsm_data, dtm_data, resolution, observer_height, cores = 1, plot = FALSE) { # AOI this_aoi \u0026lt;- sf_start %\u0026gt;% sf::st_buffer(max_distance) # Coordinates of start point x0 \u0026lt;- sf::st_coordinates(sf_start)[1] y0 \u0026lt;- sf::st_coordinates(sf_start)[2] # Observer height height0 \u0026lt;- as.numeric(terra::extract(dtm_data, cbind(x0, y0))) + observer_height # If the resolution parameter differs from the input-DSM resolution, # resample the DSM to the lower resolution. # Also, convert dsm_data_masked to \u0026quot;Raster\u0026quot; object, for faster internal calculation. if ((res(dsm_data)[1] != resolution) \u0026amp; (resolution \u0026gt;= 1)) { dsm_data_masked \u0026lt;- terra::crop(dsm_data, this_aoi) %\u0026gt;% terra::aggregate(fact = resolution/terra::res(.)) %\u0026gt;% terra::mask(terra::vect(this_aoi)) output \u0026lt;- terra::setValues(dsm_data_masked, 0) %\u0026gt;% terra::mask(dsm_data_masked) dsm_data_masked \u0026lt;- as(dsm_data_masked, \u0026quot;Raster\u0026quot;) } else { dsm_data_masked \u0026lt;- terra::crop(dsm_data, this_aoi) %\u0026gt;% terra::mask(terra::vect(this_aoi)) output \u0026lt;- terra::setValues(dsm_data_masked, 0) %\u0026gt;% terra::mask(dsm_data_masked) dsm_data_masked \u0026lt;- as(dsm_data_masked, \u0026quot;Raster\u0026quot;) } # Calculate boundaries of output raster (boundaries are adjacent to NA values) output_boundaries \u0026lt;- terra::expand(output, resolution*2) %\u0026gt;% terra::boundaries() # Get coordinates of boundaries cells and convert to list xy_stop \u0026lt;- terra::xyFromCell(output_boundaries, which(terra::values(output_boundaries) == 1)) %\u0026gt;% split(seq(nrow(.))) # Apply lineOfSight function on every point in xy_stop if (cores \u0026gt; 1) { if (Sys.info()[[\u0026quot;sysname\u0026quot;]] == \u0026quot;Windows\u0026quot;) { cl \u0026lt;- parallel::makeCluster(cores) parallel::clusterExport(cl, \u0026quot;rasterprofile\u0026quot;) parallel::clusterEvalQ(cl, library(\u0026quot;dplyr\u0026quot;)) this_LoS \u0026lt;- parallel::parLapply(cl, xy_stop, fun = lineOfSight, x0 = x0, y0 = y0, height0 = height0, resolution = resolution, dsm_data = dsm_data_masked) parallel::stopCluster(cl) } else { this_LoS \u0026lt;- parallel::mclapply(xy_stop, lineOfSight, x0 = x0, y0 = y0, height0 = height0, resolution = resolution, dsm_data = dsm_data_masked, mc.cores = cores, mc.preschedule = TRUE) } } else { this_LoS \u0026lt;- lapply(xy_stop, FUN = lineOfSight, x0 = x0, y0 = y0, height0 = height0, resolution = resolution, dsm_data = dsm_data_masked) } # Bind list this_LoS \u0026lt;- data.table::rbindlist(this_LoS) # Copy result of lapply to the output raster output[this_LoS[[1]]] \u0026lt;- this_LoS[[2]] # Compare DSM with Visibilty if (plot) { par(mfrow=c(1,2)) plot(dsm_data_masked); points(x0, y0, col = \u0026quot;red\u0026quot;, pch = 20, cex = 2) plot(output, legend = F); points(x0, y0, col = \u0026quot;red\u0026quot;, pch = 20, cex = 2) par(mfrow=c(1,1)) } return(output) } The animation below illustrates, the functionality of the viewshed function. Starting with a raster of unknown visibility (yellow), we iterative call the lineOfSight function and set the status of each raster cell to visible (green) or no-visible (white).\n Examples We need to create a start point to compare the effect of different resolutions.\n# Disable progress bar for terra::aggregate terra::terraOptions(progress = 0) sf_start \u0026lt;- sfheaders::sf_point(c(487616.2, 5455970)) %\u0026gt;% st_sf(crs = st_crs(26910)) 1. Resolution = 0.5m Output-Raster-Cells: 1 440 000\nRuntime: 0.85 seconds (cores=1: 1.80 seconds)\nTotal visibility: 11.9%\nviewshed_1 \u0026lt;- viewshed(sf_start = sf_start, max_distance = 300, dsm_data = filled_dsm, dtm_data = DTM, resolution = 0.5, observer_height = 1.8, cores = 10, plot = TRUE)  2. Resolution = 1m Output-Raster-Cells: 360 000\nRuntime: 0.45 seconds (cores=1: 0.75 seconds)\nTotal visibility: 12.4%\nviewshed_2 \u0026lt;- viewshed(sf_start = sf_start, max_distance = 300, dsm_data = filled_dsm, dtm_data = DTM, resolution = 1, observer_height = 1.8, cores = 10, plot = TRUE)  3. Resolution = 2m Output-Raster-Cells: 90 000\nRuntime: 0.35 seconds (cores=1: 0.40 seconds)\nTotal visibility: 12.8%\nviewshed_3 \u0026lt;- viewshed(sf_start = sf_start, max_distance = 300, dsm_data = filled_dsm, dtm_data = DTM, resolution = 2, observer_height = 1.8, cores = 5, plot = TRUE)  4. Resolution = 5m Output-Raster-Cells: 14 400\nRuntime: 0.22 seconds (cores=1: 0.18 seconds)\nTotal visibility: 14.6%\nviewshed_4 \u0026lt;- viewshed(sf_start = sf_start, max_distance = 300, dsm_data = filled_dsm, dtm_data = DTM, resolution = 5, observer_height = 1.8, cores = 2, plot = TRUE)    Network Visible Greenspace One practical application of the viewshed algorithm is, to calculate the visible neighborhood greenness of an observer, by analyzing visible greenness along roads and paths in the neighborhood.\nGreenspace Mask To determine the level of greenness for the visible cells in a viewshed, we need to define green and no-green pixels. For this purpose we will be using the Vancouver Land Cover Classification 2014 - 2m LiDAR (Raster). This data can be opened using ArcGIS and exported as TIFF for further analysis. From the documentation we can read the class values as follows:\n  Value  Level 1  Level 2  Level 3  Criteria      1  Built-up  Buildings   Identified using shape/size, shadow cast, height, relative canopy height, texture.    2   Paved   Everything from sidewalks and alleys to highways.    3   Other Built   Not concrete/asphalt built surfaces or building roofs. Sports surfaces (artificial turf and running tacks), possibly transit or rail areas, other impervious surfaces, etc.    4  Bare  Barren   Beaches, alpine rock, shoreline rock, etc. Lack of vegetation. Likely not soil (colour/context suggests no organic matter and/or imperviousness). Also quarries, gravel pits, dirt roads.    5   Soil   Agricultural soils (could be light or dark), cleared/open areas where darker colours indicate organic matter present (as compared to, e.g. sand), potentially riverine/alluvial deposits.    6  Vegetation  Tree canopy  Coniferous  Predominantly coniferous (\u0026gt;75%)    7    Deciduous  Predominantly deciduous (\u0026gt;75%)    8    Shrub  Woody, leafy, and generally rough-textured vegetation shorter than trees (approx. \u0026lt;3-4m), taller than grass.    9   Grass-herb  Modified Grass-herb  Crops, golf course greens, city park grass, lawns, etc.    10    Natural Grass-herb  Alpine meadows, near-shore grass areas, bog/wetland areas.    11   Non-photosynthetic vegetation   Dead grass, drought stressed vegetation, could include log    12  Water    Lakes, rivers, inlets, irrigation channels, retention ponds, pools, etc.    13  Shadow    Dark pixels with v/ low reflectance values. Image features not easily visible. Compare w/ RapidEye image for shadow    14  Clouds/Ice    Very bright pixels, that are not high-reflectance features from built-up areas.     For demonstration purpose I will use all vegetation classes as one criteria (green vs. no-green).\n# Load LandCover landCover \u0026lt;- rast(file.path(workdir, \u0026quot;LCC2014_2m_LiDAR1.tif\u0026quot;)) # Select Vegetation greenspace \u0026lt;- landCover %in% c(6:10); invisible(gc()) # Plot to compare LandCover and vegetation mask par(mfrow = c(1,2)) landCover %\u0026gt;% crop(dsm_clip) %\u0026gt;% plot(legend = FALSE) points(st_coordinates(sf_start)[1], st_coordinates(sf_start)[2], col = \u0026quot;blue\u0026quot;, cex = 3, pch = 20) greenspace %\u0026gt;% crop(dsm_clip) %\u0026gt;% plot(legend = FALSE) points(st_coordinates(sf_start)[1], st_coordinates(sf_start)[2], col = \u0026quot;blue\u0026quot;, cex = 3, pch = 20)  Green Visibility Index The gvi (Green Visibility Index; (Labib, Huck, and Lindley 2021)) function returns the proportion of visible greenspace to total visibility. The values range between 0 and 1, where 0 = no green cells are visible, and 1 = all of the visible cells are green. Applying the visibleGreen function on the viewshed_1 object calculated above returns 0.91, meaning that 91% of the visible area is vegetated.\nIn the original paper of Labib, Huck, and Lindley (2021) the authors also applied a distance decay function, to account for the reducing visual prominence of an object in space with increasing distance from the observer. However, I will address this issue in another post about distance decay models.\ngvi \u0026lt;- function(viewshed, greenspace) { # Get XY coordinates that are visible xy \u0026lt;- viewshed %\u0026gt;% terra::xyFromCell(which(viewshed[] == 1)) # Intersect XY with greenspace mask output \u0026lt;- greenspace[terra::cellFromXY(greenspace, xy)] %\u0026gt;% unlist(use.names = FALSE) # Proportion of visible green return(sum(output == 1) / length(output)) }  Network Analysis We will use the DRIGLUCoSE R package from our recent publication to calculate a road network, and finally asses visible greenspace along the network. For a detailed explanation of the DRIGLUCoSE package see the GitHub repository.\n# Download and process road network from OSM data aoi.osm \u0026lt;- DRIGLUCoSE::osm_roads(x = sf_start, dist = 10, speed = 75) # Calculate isodistances aoi.isodistances \u0026lt;- DRIGLUCoSE::isodistances(x = sf_start %\u0026gt;% mutate(tag = 1), tag = \u0026quot;tag\u0026quot;, road_network = aoi.osm, speed = 75, isochrones_seq = seq(1, 10, 1)) In the figure below the isodistances are being illustrated. The red point represents the starting point. We will calculate visible greenspace proportion every 10m.\nTo evaluate network visibility, we will write a new function networkVisibleGreenspace to combine all previous steps to a single point along the network.\nnetworkVisibleGreenspace \u0026lt;- function(x, isodistance, greenspace, dsm_data, dtm_data, resolution, max_distance, observer_height, cores, plot = FALSE) { # 1. Calculate viewshed this_viewshed \u0026lt;- viewshed(sf_start = x, max_distance = max_distance, dsm_data = dsm_data, dtm_data = dtm_data, resolution = resolution, observer_height = observer_height, cores = cores, plot = plot) # 2. Proportion of visible greenspace of total visibility (GVI) this_gvi \u0026lt;- gvi(viewshed = this_viewshed, greenspace = greenspace) # 3. Get time value of x from isodistance return(dplyr::tibble(time = isodistance[sf::st_nearest_feature(x, isodistance),]$time, GVI = this_gvi, X = as.numeric(st_coordinates(x)[1]), Y = as.numeric(st_coordinates(x)[2]))) } We can use the st_line_sample function to sample points along the isodistance object. In the viewshed examples above we have seen, that for resolution = 2 the computation time hardly differs if we set cores = 1. Therefore I use cores = 1 in the networkVisibleGreenspace and call it from the mclapply with parallel processing.\n# Sample points on the isodistance for every 25m all_points \u0026lt;- aoi.isodistances %\u0026gt;% sf::st_union() %\u0026gt;% sf::st_cast(\u0026quot;LINESTRING\u0026quot;) %\u0026gt;% sf::st_line_sample(density = 1/25) %\u0026gt;% sf::st_cast(\u0026quot;POINT\u0026quot;) %\u0026gt;% sf::st_as_sf() # Calculate network visibilty output \u0026lt;- all_points %\u0026gt;% split(seq(nrow(.))) %\u0026gt;% parallel::mclapply(networkVisibleGreenspace, isodistance = aoi.isodistances, greenspace = greenspace, dsm_data = filled_dsm, dtm_data = DTM, resolution = 2, max_distance = 300, observer_height = 1.8, cores = 1, plot = FALSE, mc.cores = 22, mc.preschedule = TRUE) %\u0026gt;% do.call(rbind, .)  Results The results of the networkVisibilityGreenspace is illustrated in the figure below.\nTo evaluate the mean GVI for the observer in the center, we need to summarize all measurements from the previous steps. I simply take the mean of all values, but one could also apply a linear or logistic weights function, such that the influence of a variable decreases with increasing distance, as demonstrated in our recent publication.\nround(mean(output$GVI), 2) ## [1] 0.5 A mean value of 0.5 indicates, that 50% of the visible area along the network is vegetated.\nOne big limitation of the viewshed algorithm is, that it fails to calculate eye-level visibility if the observer is underneath a tree. This is because we use a LiDAR derived DSM and calculate visibility based on the height of pixels along the lines of sight.\nThe histogram above shows, that there are a lot of points with GVI = 1. I have plotted the DSM and the GVI points along the route network in QGIS.The dark-green points are located underneath trees. Therefore, the viewshed algorithm can’t “see” beyond those trees and returns only one single visible cell, which is green. The proportion of green pixels to all visible pixels is therefore 1.\nAs already mentioned, applying a distance function might simulate the potential activity space better, since a person will most likely use the road/path in front of his/her place of residence more often than the road 10 minutes away. I will talk about this issue in a different post and provide a solution using the mosaic R package.\nHowever, we can see a high diversity of GVI values in the example above, in that the northern half has higher visible greenness. Therefore, future research may also incorporate actual activity space measurements instead of potential activity space models, to further analyze where (and why) participants spend time and thus improve the understanding of greenspace related health effects.\n  Conclusion Data acquisition and processing with lidR and terra is simple and fast using R as the only tool. The implementation of a parallel viewshed algorithm has proven to be very light-weighted and fast. Using a lower resolution significantly reduces model runtime. However, even at highest resolution, the runtime is acceptable. The effect of multiprocessing is significant only with high resolution or very large values of max_distance. Using this algorithm in a large scale study at high resolution appears to be practical. Compared to model 1, model 4 has an increase in visible area from 11.9% to 14.6%. The results of the other models are closer to model 1. In my opinion the trade-off between loss of accuracy for an increase in speed is acceptable down to 2m. But reducing the resolution to 5m or even more might only be worth it, if a lot of observations need to be calculated or/and for large values of max_distance, since the computation time hardly differs from 2m resolution. I would suggest comparing a few points with 0.5m, 1m, 2m and 5m resolution.\nOne mayor limitation of this method is, that it fails to calculate eye-level visibility, if the observer is located underneath a tree.\nA simple implementation of the viewshed analysis into a route network analysis served as a practical example for researching greenspace exposure.\n References Chamberlain, Brent C., and Michael J. Meitner. 2013. “A Route-Based Visibility Analysis for Landscape Management.” Landscape and Urban Planning 111 (March): 13–24. https://doi.org/10.1016/j.landurbplan.2012.12.004.  Dzhambov, Angel M., Matthew H.E.M. Browning, Iana Markevych, Terry Hartig, and Peter Lercher. 2020. “Analytical Approaches to Testing Pathways Linking Greenspace to Health: A Scoping Review of the Empirical Literature.” Environmental Research 186 (July): 109613. https://doi.org/10.1016/j.envres.2020.109613.  Khosravipour, Anahita, Andrew K. Skidmore, Martin Isenburg, Tiejun Wang, and Yousif A. Hussin. 2014. “Generating Pit-Free Canopy Height Models from Airborne Lidar.” Photogrammetric Engineering \u0026amp; Remote Sensing 80 (9): 863–72. https://doi.org/10.14358/pers.80.9.863.  Labib, S.M., Jonny J. Huck, and Sarah Lindley. 2021. “Modelling and Mapping Eye-Level Greenness Visibility Exposure Using Multi-Source Data at High Spatial Resolutions.” Science of The Total Environment 755 (February): 143050. https://doi.org/10.1016/j.scitotenv.2020.143050.  Labib, S.M., Sarah Lindley, and Jonny J. Huck. 2020. “Spatial Dimensions of the Influence of Urban Green-Blue Spaces on Human Health: A Systematic Review.” Environmental Research 180 (January): 108869. https://doi.org/10.1016/j.envres.2019.108869.  Markevych, Iana, Julia Schoierer, Terry Hartig, Alexandra Chudnovsky, Perry Hystad, Angel M. Dzhambov, Sjerp de Vries, et al. 2017. “Exploring Pathways Linking Greenspace to Health: Theoretical and Methodological Guidance.” Environmental Research 158 (October): 301–17. https://doi.org/10.1016/j.envres.2017.06.028.  Roussel, Jean-Romain, David Auty, Nicholas C. Coops, Piotr Tompalski, Tristan R.H. Goodbody, Andrew Sánchez Meador, Jean-François Bourdon, Florian de Boissieu, and Alexis Achim. 2020. “lidR: An R Package for Analysis of Airborne Laser Scanning (ALS) Data.” Remote Sensing of Environment 251 (December): 112061. https://doi.org/10.1016/j.rse.2020.112061.  Tabrizian, Payam, Perver K. Baran, Derek Van Berkel, Helena Mitasova, and Ross Meentemeyer. 2020. “Modeling Restorative Potential of Urban Environments by Coupling Viewscape Analysis of Lidar Data with Experiments in Immersive Virtual Environments.” Landscape and Urban Planning 195 (March): 103704. https://doi.org/10.1016/j.landurbplan.2019.103704.    ","date":1615766400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615830206,"objectID":"8d74768c3da390e3b68e8c013a7711b8","permalink":"/post/visible-greenness-exposure/","publishdate":"2021-03-15T00:00:00Z","relpermalink":"/post/visible-greenness-exposure/","section":"post","summary":"Exposure to residential greenness or green spaces such as parks or gardens are beneficial for multiple measures of health. One type of greenspace exposure is visibility, referring to the visual perception of greenness. In this post I will demonstrate, how to conduct a viewshed based visibility analysis.","tags":["R","GIS","Greenspace","Health Geography","LiDAR"],"title":"Visible Greenness Exposure","type":"post"},{"authors":[],"categories":[],"content":"Klicke hier für die mobilfreundliche Version 📱\n COVID-19 Bewegungsradius Stand: 15.1.2020 Die 15-Kilomenter Regel, nachdem sich Bewohner mit einer 7-Tage Inzidenz von über 200 nur noch 15 km um ihren Wohnort bewegen dürfen, sorgt für Verwirrung. Diese App soll dabei helfen, den individuellen Bewegungsradius zu ermitteln.\nZunächst wird die aktuelle 7-Tage-Inzidenz für jeden Landkreis gedownloaded und in zwei Kategorien eingeteilt: \u0026lt; 200 und \u0026gt;= 200. Anschließend wird die Adresse georeferenziert und ein 15 km Buffer wird um die Gemeinde, bzw. den Landkreis der Adresse, oder auch die Adresse selbst gelegt.\nDer genaue Wert der 7-Tage-Inzidenz, sowie die Verfügbarkeiten von Intensivstationbetten (ITS) kann durch Anklicken eines Landkreisen ausgelesen werden.\nDie Corona-Regeln in den Bundesländern    Bundesland 15-km Regel Mehr Infos     Baden-Württemberg Wird aktuell nicht umgesetzt url   Bayern Ab der Gemeindegrenze url   Berlin Ab der Stadtgrenze url   Brandenburg Für touristische Ausflüge, Sport und Bewegung im Freien, um den jeweiligen Landkreis bzw. die kreisfreie Stadt url   Bremen Wird aktuell nicht umgesetzt url   Hamburg Wird aktuell nicht umgesetzt url   Hessen Ab der Gemeindegrenze; betroffene Landkreise: Gießen, Limburg-Weilburg, Fulda, Vogelsbergkreis url   Mecklenburg-Vorpommern Ab der Wohnadresse url   Niedersachsen Ab der Wohnadresse, durch Kommunen geregelt url   Nordrhein-Westfalen Ab der Gemeindegrenze; betroffene Landkreise: Höxter, Minden-Lübbecke, Oberbergischer Kreis, Recklinghausen url   Rheinland-Pfalz Ab der Gemeindegrenze, durch Kommunen geregelt url   Saarland Für touristische Ausflüge, um die Wohnadresse url   Sachsen Ab der Wohnadresse url   Sachsen-Anhalt Ab der Gemeindegrenze url   Schleswig-Holstein Ab der Gemeindegrenze, durch Kommunen geregelt url   Thüringen Ab der Gemeindegrenze, nicht verpflichtend url    Credits  Geocoding D. Kisler GPS locater via Dr. Tom August’s shiny geolocation Javascript script API Aufrufe zu den aktuellen COVID-19 Fallzahlen und ITS-Betten via entorb’s GitHub Seite  Disclaimer Dieses Tool dient nur zu Unterhaltungszwecken und stellt keine medizinische, rechtliche oder sonstige Form der Beratung dar. Benutzer sollten sich auf die offiziellen Richtlinien und Empfehlungen ihrer nationalen, staatlichen und lokalen Behörden beziehen. Es werden keinerlei personenbezogener Daten gespeichert.\n","date":1610668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610732606,"objectID":"746e1944d06a4c270879ba64b2dd144a","permalink":"/post/covid-19-15km-radius-webapp/","publishdate":"2021-01-15T00:00:00Z","relpermalink":"/post/covid-19-15km-radius-webapp/","section":"post","summary":"Klicke hier für die mobilfreundliche Version 📱\n COVID-19 Bewegungsradius Stand: 15.1.2020 Die 15-Kilomenter Regel, nachdem sich Bewohner mit einer 7-Tage Inzidenz von über 200 nur noch 15 km um ihren Wohnort bewegen dürfen, sorgt für Verwirrung.","tags":["COVID-19","GIS","R","Shiny"],"title":"COVID-19: 15km Radius WebApp","type":"post"},{"authors":["Christopher Scarpone","Sebastian Brinkmann","Tim Große","Daniel Sonnenwald","Martin Fuchs","Blake Byron Walker"],"categories":null,"content":"","date":1597276800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597276800,"objectID":"6a5442ef4ce0e1051155336bfa8ac44b","permalink":"/publication/scarpone2020/","publishdate":"2020-08-13T00:00:00Z","relpermalink":"/publication/scarpone2020/","section":"publication","summary":"As of 13 July 2020, 12.9 million COVID-19 cases have been reported worldwide. Prior studies have demonstrated that local socioeconomic and built environment characteristics may significantly contribute to viral transmission and incidence rates, thereby accounting for some of the spatial variation observed. Due to uncertainties, non-linearities, and multiple interaction effects observed in the associations between COVID-19 incidence and socioeconomic, infrastructural, and built environment characteristics, we present a structured multimethod approach for analysing cross-sectional incidence data within in an Exploratory Spatial Data Analysis (ESDA) framework at the NUTS3 (county) scale.","tags":["COVID-19","SARS-CoV-2","GIS","Built environment","Socioeconomic status","Machine learning","Infectious disease","Exploratory Spatial Data Analysis (ESDA)"],"title":"A multimethod approach for county-scale geospatial analysis of emerging infectious diseases. A cross-sectional case study of COVID-19 incidence in Germany","type":"publication"},{"authors":["Sebastian Brinkmann"],"categories":null,"content":"In 2001 a project has been created to transform the former steel production site in Belval, Luxembourg into the Cité des Sciences. In 2015 the new campus has been opened. In this analysis I want to explore how this topic is being represented in the news.\nTherefore I first collected the top 58 news articles from Google News. The texts have been translated to English with DeepL and structured in a .txt document like so:\nTitle: Title_Name\rDATE: dd.mm.yyyy\r.\r. Text\r.\rTitle: Title_Name\rDATE: dd.mm.yyyy\r.\r. Text\r.\r Wordcloud Next a Wordcloud with the word frequency of the whole corpus has been created: We can already see that the new campus is of high importance. But also, the look into the future (\u0026ldquo;2022\u0026rdquo;, \u0026ldquo;future\u0026rdquo;), and the acknowledgement of its history (\u0026ldquo;furnace\u0026rdquo;, \u0026ldquo;steel\u0026rdquo;, \u0026ldquo;industrial\u0026rdquo;\u0026hellip;) are often thematised.\nTerm Frequency-Inverse Document Frequency At this point the corpus does not contain many articles for 2014 and 2015. Therefore these articles have been combined for the further analysis. The next figure shows the number of articles per year: With the wordcloud we explored the word frequency of the whole corpus. To analyse the keywords of each year, a term frequency-inverse document frequency has been conducted: Structural Topic Model Next a Structural Topic Model (STM) has been applied on the data set. From the previous steps we already have gained an understanding of the complexity of the coverage of reports about Belval. Therefore, we knew that there are not that many different topics. After an iterative process of setting the parameter K (number of topics) and interpreting the results, I set K = 6. These 6 topics have been labeled manually. To evaluate the importance and the change over time of these topics, the topic of each article within the corpus has been predicted. The result is shown in the final figure: The most frequent articles are those that deal with the university campus in Belval itself. The second most frequent type of article is the one dealing with structural change, i.e. the transformation from a former steel industry location to the Cité des Sciences, the city of science. It should be emphasized that articles on this topic predominantly highlight the positive implementation of structural change. This is followed by articles on the topic of culture, although it is clearly visible here that there has been increased reporting on this area since 2019. This is due to the fact that this year Belval was admitted to the Capital of Culture 2022. This analysis was complemented by a qualitative interview with a partner from the University of Luxembourg about the Belval project.\nThe code is available on GitHub.\n","date":1588809600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588809600,"objectID":"05d0968620ba9fe534b3989f7bbe17bf","permalink":"/post/text-mining-belval/","publishdate":"2020-05-07T00:00:00Z","relpermalink":"/post/text-mining-belval/","section":"post","summary":"In 2001 a project has been created to transform the former steel production site in Belval, Luxembourg into the Cité des Sciences. In 2015 the new campus has been opened. In this analysis I'm using a Structural Topic Model (STM) to explore how this topic is being represented in the news.","tags":["STM","Text Mining","R","Tidyverse"],"title":"Text Mining Belval Campus","type":"post"}]